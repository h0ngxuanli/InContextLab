{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
       "            <style>\n",
       "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
       "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
       "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
       "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
       "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
       "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2)); color: black; }\n",
       "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
       "                .token:hover .tooltip { display: block; }\n",
       "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
       "            </style>\n",
       "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
       "            <div id=\"demonstration-container\">\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 1.000</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666865348816\" data-score=\"0.1666666865348816\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666716337204\" data-score=\"0.1666666716337204\">\n",
       "                                Ġarticle\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666716337204\" data-score=\"0.1666666716337204\">\n",
       "                                Ġexplained\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666865348816\" data-score=\"0.1666666865348816\">\n",
       "                                ĠAI\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666716337204\" data-score=\"0.1666666716337204\">\n",
       "                                Ġclearly\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.1666666716337204\" data-score=\"0.1666666716337204\">\n",
       "                                .\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.033</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000001788139343\" data-score=\"0.20000001788139343\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000000298023224\" data-score=\"0.20000000298023224\">\n",
       "                                Ġnovel\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000000298023224\" data-score=\"0.20000000298023224\">\n",
       "                                Ġwas\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000001788139343\" data-score=\"0.20000001788139343\">\n",
       "                                Ġthrilling\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000000298023224\" data-score=\"0.20000000298023224\">\n",
       "                                .\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.008</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000001788139343\" data-score=\"0.20000001788139343\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000000298023224\" data-score=\"0.20000000298023224\">\n",
       "                                Ġmovie\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000000298023224\" data-score=\"0.20000000298023224\">\n",
       "                                Ġwas\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.20000001788139343\" data-score=\"0.20000001788139343\">\n",
       "                                Ġgreat\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.19999998807907104\" data-score=\"0.19999998807907104\">\n",
       "                                .\n",
       "                                <span class=\"tooltip\">Score: 0.20</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from IPython.display import HTML, display\n",
    "from jinja2 import Template\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    X_TO_Y = \"X->Y->theta\"\n",
    "    Y_TO_X = \"Y->X->theta\"\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 10000\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def compute_token_contributions(self, text: str) -> List[Dict]:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.config.device)\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        attentions = outputs.attentions\n",
    "        layer_contributions = [\n",
    "            layer_att.mean(dim=1).sum(dim=2)\n",
    "            for layer_att in attentions\n",
    "        ]\n",
    "\n",
    "        num_layers = len(attentions)\n",
    "        layer_weights = torch.linspace(0.1, 1.0, steps=num_layers).to(self.config.device)\n",
    "        weighted_contributions = torch.stack(layer_contributions, dim=0) * layer_weights[:, None, None]\n",
    "        token_contributions = weighted_contributions.sum(dim=0)\n",
    "\n",
    "        normalized_contributions = token_contributions / token_contributions.sum(dim=1, keepdim=True)\n",
    "\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "        return [{\"token\": token, \"score\": float(score)} \n",
    "                for token, score in zip(tokens, normalized_contributions.squeeze().tolist())]\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        new_tokens = []\n",
    "        for task in tasks:\n",
    "            task_tokens = [f\"<{task}_token_{i}>\" for i in range(self.config.n_prefix_tokens)]\n",
    "            new_tokens.extend(task_tokens)\n",
    "        \n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        # Add concept tokens and get their indices\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        \n",
    "        # Get the embedding layer parameters - we want just the new token embeddings\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        # Get indices of the new tokens we added\n",
    "        new_token_ids = [self.tokenizer.convert_tokens_to_ids(token) for token in concept_tokens]\n",
    "        \n",
    "        # Create optimizer only for the new token embeddings\n",
    "        optimizer = AdamW([\n",
    "            {\n",
    "                'params': embed_layer.weight[new_token_ids],\n",
    "                'lr': self.config.learning_rate\n",
    "            }\n",
    "        ])\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for item in batch:\n",
    "                task_idx = tasks.index(item[\"task\"])\n",
    "                loss = self._compute_batch_loss(item, concept_tokens[task_idx], direction)\n",
    "                loss = loss / len(batch)  # Normalize by batch size\n",
    "                total_loss += loss\n",
    "\n",
    "            print(f\"Loss value: {total_loss.item()}\")\n",
    "            print(f\"Grad norms: {[p.grad.norm().item() for p in optimizer.param_groups[0]['params']]}\")\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def _compute_batch_loss(self, item: Dict, concept_token: str, direction: CausalDirection) -> torch.Tensor:\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            inputs = self._prepare_xy_input(item[\"text\"], concept_token) \n",
    "            target_ids = self.tokenizer(item[\"label\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "        else:\n",
    "            inputs = self._prepare_yx_input(item[\"label\"], concept_token)\n",
    "            target_ids = self.tokenizer(item[\"text\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        # Use CrossEntropyLoss directly on logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        shift_logits = outputs.logits[..., :-1, :].contiguous()\n",
    "        shift_labels = target_ids[..., 1:].contiguous()\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        return loss\n",
    "    # def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "    #     concept_tokens = self.add_concept_tokens(tasks)\n",
    "    #     optimizer = AdamW(\n",
    "    #         [p for n, p in self.model.named_parameters() if \"wte\" in n],\n",
    "    #         lr=self.config.learning_rate\n",
    "    #     )\n",
    "\n",
    "    #     for step in range(self.config.num_train_steps):\n",
    "    #         batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "    #         total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "\n",
    "    #         for item in batch:\n",
    "    #             loss = self._compute_batch_loss(item, concept_tokens[tasks.index(item[\"task\"])], direction)\n",
    "    #             total_loss += loss\n",
    "\n",
    "    #         optimizer.zero_grad()\n",
    "            \n",
    "    #         total_loss.backward()\n",
    "\n",
    "    #         for param_group in optimizer.param_groups:\n",
    "    #             for param in param_group['params']:\n",
    "    #                 if param.grad is None:\n",
    "    #                     continue\n",
    "    #                 else:\n",
    "    #                     print(param.grad)\n",
    "    #         optimizer.step()\n",
    "\n",
    "    # def _compute_batch_loss(self, item: Dict, concept_token: str, direction: CausalDirection) -> torch.Tensor:\n",
    "    #     if direction == CausalDirection.X_TO_Y:\n",
    "    #         inputs = self._prepare_xy_input(item[\"text\"], concept_token)\n",
    "    #         labels = self.tokenizer(item[\"label\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "    #     else:\n",
    "    #         inputs = self._prepare_yx_input(item[\"label\"], concept_token)\n",
    "    #         labels = self.tokenizer(item[\"text\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "\n",
    "    #     outputs = self.model(**inputs, labels=labels)\n",
    "    #     return outputs.loss\n",
    "\n",
    "    def _prepare_xy_input(self, text: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {text}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "    def _prepare_yx_input(self, label: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {label}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "class DemonstrationSelector:\n",
    "    def __init__(self, concept_learner: ConceptLearner):\n",
    "        self.concept_learner = concept_learner\n",
    "\n",
    "    def select_demonstrations(self, candidates: List[Dict], k: int):\n",
    "        scores = [(self._compute_concept_score(c), c) for c in candidates]\n",
    "        # Extract just the scores for normalization\n",
    "        score_values = [s for s, _ in scores]\n",
    "        \n",
    "        # Find min and max scores\n",
    "        min_score = min(score_values)\n",
    "        max_score = max(score_values)\n",
    "        \n",
    "        # Handle edge case where all scores are the same\n",
    "        if max_score == min_score:\n",
    "            return [(1.0, concept) for _, concept in scores]\n",
    "        \n",
    "        # Normalize scores using min-max normalization\n",
    "        scores = [\n",
    "            ((s - min_score) / (max_score - min_score), c)\n",
    "            for s, c in scores\n",
    "        ]\n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [c for _, c in scores[:k]], [s for s, _ in scores[:k]]\n",
    "\n",
    "    def _compute_concept_score(self, candidate: Dict):\n",
    "        inputs = self.concept_learner.tokenizer(candidate[\"demonstration\"], return_tensors=\"pt\")\n",
    "        outputs = self.concept_learner.model(**inputs)\n",
    "        logits = outputs.logits[:, :-1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        target_ids = self.concept_learner.tokenizer(candidate[\"label\"], return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "        scores = [probs[0, i, target_id].item() for i, target_id in enumerate(target_ids)]\n",
    "        return sum(scores) / len(scores)\n",
    "\n",
    "    def evaluate_demonstrations(self, test_set: List[Dict], selected_demos: List[Dict]):\n",
    "        total_loss = 0\n",
    "        for example in test_set:\n",
    "            inputs = self.concept_learner.tokenizer(\n",
    "                selected_demos + [example[\"demonstration\"]], return_tensors=\"pt\", truncation=True\n",
    "            )\n",
    "            outputs = self.concept_learner.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            total_loss += outputs.loss.item()\n",
    "        avg_loss = total_loss / len(test_set)\n",
    "        print(f\"Evaluation Loss: {avg_loss}\")\n",
    "        return avg_loss\n",
    "\n",
    "class DashboardVisualizer:\n",
    "    def __init__(self, demonstration_scores):\n",
    "        self.demonstration_scores = demonstration_scores\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        html_template = '''\n",
    "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
    "            <style>\n",
    "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
    "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
    "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
    "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
    "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
    "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2)); color: black; }\n",
    "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
    "                .token:hover .tooltip { display: block; }\n",
    "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
    "            </style>\n",
    "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
    "            <div id=\"demonstration-container\">\n",
    "                {% for demo in demonstration_scores %}\n",
    "                <div class=\"demonstration-card\">\n",
    "                    <div class=\"demonstration-header\">Demonstration Score: {{ \"%.3f\"|format(demo.score) }}</div>\n",
    "                    <div>\n",
    "                        <b>Token Contributions:</b>\n",
    "                        <div class=\"token-container\">\n",
    "                            {% for token in demo.token_contributions %}\n",
    "                            <div class=\"token\" style=\"--score: {{ token.score }}\" data-score=\"{{ token.score }}\">\n",
    "                                {{ token.token }}\n",
    "                                <span class=\"tooltip\">Score: {{ \"%.2f\"|format(token.score) }}</span>\n",
    "                            </div>\n",
    "                            {% endfor %}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        template = Template(html_template)\n",
    "        rendered_html = template.render(demonstration_scores=self.demonstration_scores)\n",
    "        display(HTML(rendered_html))\n",
    "\n",
    "\n",
    "set_global_seed(42)\n",
    "config = ModelConfig(model_name=\"gpt2-xl\", n_prefix_tokens=5, learning_rate=1e-4)\n",
    "concept_learner = ConceptLearner(config)\n",
    "demonstration_selector = DemonstrationSelector(concept_learner)\n",
    "\n",
    "candidates = [\n",
    "    {\"demonstration\": \"The movie was great.\", \"label\": \"positive\"},\n",
    "    {\"demonstration\": \"The book was boring.\", \"label\": \"negative\"},\n",
    "    {\"demonstration\": \"The article explained AI clearly.\", \"label\": \"informative\"},\n",
    "    {\"demonstration\": \"The novel was thrilling.\", \"label\": \"exciting\"},\n",
    "]\n",
    "\n",
    "selected_demos, selected_demos_scores = demonstration_selector.select_demonstrations(candidates, k=3)\n",
    "demonstration_scores = []\n",
    "for demo, demo_score in zip(selected_demos, selected_demos_scores):\n",
    "    tokens = demo[\"demonstration\"]\n",
    "    token_contributions = concept_learner.compute_token_contributions(tokens)\n",
    "    # token_contributions = [{\"token\": token, \"score\": random.uniform(0, 1)} for token in tokens]\n",
    "    demonstration_scores.append({\"score\": demo_score, \"token_contributions\": token_contributions})\n",
    "\n",
    "dashboard = DashboardVisualizer(demonstration_scores=demonstration_scores)\n",
    "dashboard.create_dashboard()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLMs as Latent Variable Models\n",
    "\n",
    "This paper proposes treating LLMs as latent variable models that can automatically learn and use task concepts to select better demonstrations.\n",
    "\n",
    "## Framework Steps\n",
    "\n",
    "### 1. Latent Concept Learning\n",
    "**Goal**: Learn task-specific concept tokens that capture what makes examples good demonstrations.\n",
    "\n",
    "**How it works**:\n",
    "- Add new \"concept tokens\" to the model's vocabulary \n",
    "- Fine-tune only these new token embeddings on the task\n",
    "- Model learns to encode task information in these tokens\n",
    "- Can be done with a smaller proxy model (like GPT-2) to save compute\n",
    "\n",
    "**Mathematically**:\n",
    "$L(\\hat{\\theta}^d) = \\mathbb{E}_{X,Y}[\\ell(X, Y; \\hat{\\theta}^d)]$\n",
    "\n",
    "where $\\hat{\\theta}^d$ represents the learned concept tokens for task d.\n",
    "\n",
    "### 2. Smart Sample Selection\n",
    "**Goal**: Find the best examples to use as demonstrations.\n",
    "\n",
    "**How it works**:\n",
    "- For each potential demonstration in validation set\n",
    "- Check how likely it is to generate the learned concept tokens\n",
    "- Select examples with highest probability\n",
    "- These examples best represent the task concept\n",
    "\n",
    "**Key Metric**:\n",
    "$P_M^d(\\hat{\\theta}^d|w_{1:t})$ - Probability of concept tokens given the input\n",
    "\n",
    "### 3. Probability Calculation\n",
    "**Goal**: Understand how well demonstrations capture task information.\n",
    "\n",
    "**How it works**:\n",
    "- Model integrates over all possible task concepts\n",
    "- Learned concept tokens help guide this integration\n",
    "- Higher probability means better demonstration quality\n",
    "\n",
    "**Core Equation**:\n",
    "$P_M^d(w_{t+1:T}|w_{1:t}) = \\int_{\\Theta} P_M^d(w_{t+1:T}|\\theta)P_M^d(\\theta|w_{1:t})d\\theta$\n",
    "\n",
    "### 4. Using with Any LLM\n",
    "**Goal**: Apply selected demonstrations to improve any LLM's performance.\n",
    "\n",
    "**How it works**:\n",
    "- Take best demonstrations found using small proxy model\n",
    "- Use them as examples in prompt for any larger LLM\n",
    "- No need to retrain or modify target LLM\n",
    "- Works because demonstrations capture fundamental task concepts\n",
    "\n",
    "**Benefits**:\n",
    "- Automated selection process\n",
    "- More optimal demonstrations\n",
    "- Better task performance\n",
    "- Transferable across different LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 8.225733757019043\n",
      "{'token': '<sentiment_token_0>', 'score': 0.7581888437271118}\n",
      "{'token': 'Ġ', 'score': 0.06689581274986267}\n",
      "{'token': '<sentiment_token_1>', 'score': 0.1064826026558876}\n",
      "{'token': 'Ġ', 'score': 0.0388786718249321}\n",
      "{'token': '<sentiment_token_2>', 'score': 0.02955404669046402}\n",
      "{'token': 'Ġ', 'score': 0.0}\n",
      "{'token': '<sentiment_token_3>', 'score': 0.0}\n",
      "{'token': 'Ġ', 'score': 0.0}\n",
      "{'token': '<sentiment_token_4>', 'score': 0.0}\n",
      "{'token': 'ĠThe', 'score': 0.0}\n",
      "{'token': 'Ġmovie', 'score': 0.0}\n",
      "{'token': 'Ġwas', 'score': 0.0}\n",
      "{'token': 'Ġgreat', 'score': 0.0}\n",
      "{'token': '.', 'score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    X_TO_Y = \"X->Y->theta\"\n",
    "    Y_TO_X = \"Y->X->theta\"\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 1\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        new_tokens = []\n",
    "        for task in tasks:\n",
    "            task_tokens = [f\"<{task}_token_{i}>\" for i in range(self.config.n_prefix_tokens)]\n",
    "            new_tokens.extend(task_tokens)\n",
    "        \n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        # Add concept tokens and get their indices\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        \n",
    "        # Get the embedding layer\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        \n",
    "        # Create parameter groups for the optimizer - only optimize the embedding weights\n",
    "        optimizer = AdamW([\n",
    "            {'params': embed_layer.weight, 'lr': self.config.learning_rate}\n",
    "        ])\n",
    "\n",
    "        # Create a mask for the embeddings we want to train\n",
    "        new_token_ids = torch.tensor([\n",
    "            self.tokenizer.convert_tokens_to_ids(token) \n",
    "            for token in concept_tokens\n",
    "        ], device=self.config.device)\n",
    "        \n",
    "        # Create a mask for freezing gradients of tokens we don't want to train\n",
    "        grad_mask = torch.zeros_like(embed_layer.weight, dtype=torch.bool)\n",
    "        grad_mask[new_token_ids] = True\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item, concept_tokens, direction, tasks)\n",
    "                loss = loss / len(batch)  # Normalize by batch size\n",
    "                total_loss += loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            \n",
    "            # Zero out gradients for tokens we don't want to train\n",
    "            embed_layer.weight.grad[~grad_mask] = 0\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 200 == 0:\n",
    "                print(f\"Step {step}, Loss: {total_loss.item()}\")\n",
    "\n",
    "    def _compute_batch_loss(self, item: Dict, concept_tokens: List[str], direction: CausalDirection, tasks: List[str]) -> torch.Tensor:\n",
    "        task_idx = tasks.index(item[\"task\"])\n",
    "        concept_token = concept_tokens[task_idx]\n",
    "\n",
    "        # We will combine X and Y into one sequence for language modeling.\n",
    "        # If direction == X_TO_Y, the model sees concept_token + X + Y+<eos> as input \n",
    "        # and tries to predict each next token.\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            sequence = f\"{concept_token} {item['text']} {item['label']} {self.tokenizer.eos_token}\"\n",
    "        else:\n",
    "            sequence = f\"{concept_token} {item['label']} {item['text']} {self.tokenizer.eos_token}\"\n",
    "\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        \n",
    "        # For language modeling, targets are the same as inputs (shifted by one)\n",
    "        target_ids = inputs[\"input_ids\"]\n",
    "\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        # Next-token prediction: shift the inputs\n",
    "        shift_logits = outputs.logits[..., :-1, :].contiguous()   # [batch, seq_length-1, vocab]\n",
    "        shift_labels = target_ids[..., 1:].contiguous()           # [batch, seq_length-1]\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        return loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "    def compute_token_contributions(self, text: str, concept_tokens: List[str]) -> List[Dict]:\n",
    "        # Add concept tokens at the start of the sequence \n",
    "        concept_input = f\"{' '.join(concept_tokens)} {text}\"\n",
    "        inputs = self.tokenizer(concept_input, return_tensors=\"pt\", truncation=True, \n",
    "                            max_length=self.config.max_length).to(self.config.device)\n",
    "\n",
    "        outputs = self.model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "        attentions = outputs.attentions\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        \n",
    "        # The concept tokens are the first n tokens\n",
    "        concept_positions = list(range(len(concept_tokens)))\n",
    "        \n",
    "        # Compute token importance using attention patterns\n",
    "        num_layers = len(attentions)\n",
    "        token_contributions = torch.zeros(input_ids.size(0), device=self.config.device)\n",
    "        \n",
    "        for layer_idx, layer_attention in enumerate(attentions):\n",
    "            avg_attention = layer_attention.mean(dim=1)  # (batch, seq_len, seq_len)\n",
    "            \n",
    "            # Look at attention FROM concept token positions \n",
    "            concept_attention = avg_attention[:, concept_positions, :]\n",
    "            \n",
    "            # Aggregate contributions\n",
    "            token_scores = concept_attention.sum(dim=1)\n",
    "            token_contributions += token_scores.squeeze(0)\n",
    "        \n",
    "        # Normalize\n",
    "        token_contributions /= token_contributions.sum()\n",
    "        \n",
    "        return [{\"token\": token, \"score\": float(score)} \n",
    "                for token, score in zip(tokens, token_contributions.tolist())]\n",
    "    \n",
    "\n",
    "# Main execution\n",
    "set_global_seed(42)\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=5, learning_rate=0)\n",
    "concept_learner = ConceptLearner(config)\n",
    "\n",
    "# Prepare training data\n",
    "train_data = [\n",
    "    {\"text\": \"The movie was great.\", \"label\": \"positive\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The book was boring.\", \"label\": \"negative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The article explained AI clearly.\", \"label\": \"informative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The novel was thrilling.\", \"label\": \"exciting\", \"task\": \"sentiment\"}\n",
    "]\n",
    "\n",
    "\n",
    "# First train the model with concept tokens\n",
    "concept_tokens = concept_learner.add_concept_tokens(tasks=[\"sentiment\"])\n",
    "concept_learner.train_concept_tokens(train_data, tasks=[\"sentiment\"], direction=CausalDirection.X_TO_Y)\n",
    "\n",
    "# Then analyze contributions\n",
    "test_text = \"The movie was great.\"\n",
    "contributions = concept_learner.compute_token_contributions(test_text, concept_tokens)\n",
    "for c in contributions:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 8.225733757019043\n",
      "{'token': '<sentiment_concept_0>', 'score': 0.8478765631414027}\n",
      "{'token': '<sentiment_concept_1>', 'score': 0.1190778129942124}\n",
      "{'token': '<sentiment_concept_2>', 'score': 0.03304562386438489}\n",
      "{'token': '<sentiment_concept_3>', 'score': 0.0}\n",
      "{'token': '<sentiment_concept_4>', 'score': 0.0}\n",
      "{'token': '.', 'score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    X_TO_Y = \"X->Y->theta\"\n",
    "    Y_TO_X = \"Y->X->theta\"\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 1\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        new_tokens = [f\"<{task}_token_{i}>\" for task in tasks for i in range(self.config.n_prefix_tokens)]\n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        # Initialize new token embeddings with the mean of pre-trained embeddings\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        new_token_ids = [self.tokenizer.convert_tokens_to_ids(token) for token in new_tokens]\n",
    "        with torch.no_grad():\n",
    "            mean_embedding = embed_layer.weight.mean(dim=0)\n",
    "            for token_id in new_token_ids:\n",
    "                embed_layer.weight[token_id] = mean_embedding\n",
    "\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "\n",
    "        optimizer = AdamW([{'params': embed_layer.weight, 'lr': self.config.learning_rate}])\n",
    "        new_token_ids = torch.tensor(\n",
    "            [self.tokenizer.convert_tokens_to_ids(token) for token in concept_tokens],\n",
    "            device=self.config.device\n",
    "        )\n",
    "        \n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "            \n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item, direction, concept_tokens)\n",
    "                total_loss += loss / len(batch)\n",
    "            \n",
    "            total_loss.backward()\n",
    "            \n",
    "            # Freeze gradients for non-concept tokens\n",
    "            embed_layer.weight.grad[~torch.isin(torch.arange(embed_layer.weight.size(0), device=self.config.device), new_token_ids)] = 0\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 200 == 0:\n",
    "                print(f\"Step {step}, Loss: {total_loss.item()}\")\n",
    "\n",
    "    def _compute_batch_loss(self, item: Dict, direction: CausalDirection, concept_tokens: List[str]) -> torch.Tensor:\n",
    "        task = item[\"task\"]\n",
    "        concept_token = f\"<{task}_concept_0>\"\n",
    "        sequence = (f\"{concept_token} {item['text']} {item['label']} {self.tokenizer.eos_token}\" \n",
    "                    if direction == CausalDirection.X_TO_Y else \n",
    "                    f\"{concept_token} {item['label']} {item['text']} {self.tokenizer.eos_token}\")\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        target_ids = inputs[\"input_ids\"]\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits[..., :-1, :]\n",
    "        labels = target_ids[..., 1:]\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        return loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    \n",
    "    def compute_token_contributions(self, text: str, concept_tokens: List[str]) -> List[Dict]:\n",
    "        # Combine concept tokens with the input text\n",
    "        sequence = f\"{' '.join(concept_tokens)} {text}\"\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        outputs = self.model(**inputs, output_attentions=True)\n",
    "        attentions = outputs.attentions  # (num_layers, batch, num_heads, seq_len, seq_len)\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        # Identify positions of concept tokens\n",
    "        concept_positions = list(range(len(concept_tokens)))\n",
    "        contributions = torch.zeros(len(tokens), device=self.config.device)\n",
    "\n",
    "        # Compute token contributions using attention weights\n",
    "        for layer_attention in attentions:\n",
    "            avg_attention = layer_attention.mean(dim=1)  # Average over heads\n",
    "            concept_attention = avg_attention[:, concept_positions, :]  # Attention FROM concept tokens\n",
    "            contributions += concept_attention.sum(dim=1).squeeze(0)  # Aggregate attention\n",
    "\n",
    "        # Normalize contributions\n",
    "        contributions /= contributions.sum()\n",
    "\n",
    "        # Exclude non-semantic tokens (e.g., 'Ġ')\n",
    "        filtered_tokens = []\n",
    "        filtered_contributions = []\n",
    "        for token, score in zip(tokens, contributions.tolist()):\n",
    "            if token.strip() and not token.startswith(\"Ġ\"):  # Exclude empty or space-only tokens\n",
    "                filtered_tokens.append(token)\n",
    "                filtered_contributions.append(score)\n",
    "\n",
    "        # Renormalize filtered contributions\n",
    "        total_score = sum(filtered_contributions)\n",
    "        filtered_contributions = [score / total_score for score in filtered_contributions]\n",
    "\n",
    "        # Return filtered results\n",
    "        return [{\"token\": token, \"score\": score} for token, score in zip(filtered_tokens, filtered_contributions)]\n",
    "\n",
    "\n",
    "    # def compute_token_contributions(self, text: str, concept_tokens: List[str]) -> List[Dict]:\n",
    "    #     sequence = f\"{' '.join(concept_tokens)} {text}\"\n",
    "    #     inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "    #     outputs = self.model(**inputs, output_attentions=True)\n",
    "    #     attentions = outputs.attentions\n",
    "    #     input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "    #     tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    #     concept_positions = list(range(len(concept_tokens)))\n",
    "    #     contributions = torch.zeros(len(tokens), device=self.config.device)\n",
    "        \n",
    "    #     for layer_attention in attentions:\n",
    "    #         avg_attention = layer_attention.mean(dim=1)\n",
    "    #         concept_attention = avg_attention[:, concept_positions, :]\n",
    "    #         contributions += concept_attention.sum(dim=1).squeeze(0)\n",
    "        \n",
    "    #     contributions /= contributions.sum()\n",
    "    #     return [{\"token\": token, \"score\": float(score)} for token, score in zip(tokens, contributions.tolist())]\n",
    "\n",
    "# Usage Example\n",
    "set_global_seed(42)\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=5)\n",
    "concept_learner = ConceptLearner(config)\n",
    "\n",
    "train_data = [\n",
    "    {\"text\": \"The movie was great.\", \"label\": \"positive\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The book was boring.\", \"label\": \"negative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The article explained AI clearly.\", \"label\": \"informative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The novel was thrilling.\", \"label\": \"exciting\", \"task\": \"sentiment\"}\n",
    "]\n",
    "\n",
    "tasks = [\"sentiment\"]\n",
    "concept_learner.train_concept_tokens(train_data, tasks, direction=CausalDirection.X_TO_Y)\n",
    "\n",
    "test_text = \"The movie was great.\"\n",
    "concept_tokens = concept_learner.add_concept_tokens(tasks)\n",
    "contributions = concept_learner.compute_token_contributions(test_text, concept_tokens)\n",
    "for c in contributions:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': '<sentiment_concept_0>', 'score': 0.7581803202629089},\n",
       " {'token': 'Ġ', 'score': 0.06690854579210281},\n",
       " {'token': '<sentiment_concept_1>', 'score': 0.1064806580543518},\n",
       " {'token': 'Ġ', 'score': 0.03888070583343506},\n",
       " {'token': '<sentiment_concept_2>', 'score': 0.029549751430749893},\n",
       " {'token': 'Ġ', 'score': 0.0},\n",
       " {'token': '<sentiment_concept_3>', 'score': 0.0},\n",
       " {'token': 'Ġ', 'score': 0.0},\n",
       " {'token': '<sentiment_concept_4>', 'score': 0.0},\n",
       " {'token': 'ĠThe', 'score': 0.0},\n",
       " {'token': 'Ġmovie', 'score': 0.0},\n",
       " {'token': 'Ġwas', 'score': 0.0},\n",
       " {'token': 'Ġgreat', 'score': 0.0},\n",
       " {'token': '.', 'score': 0.0}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihongxuan/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n",
      "/Users/lihongxuan/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 8.225732803344727\n",
      "<sentiment_concept> The movie was great.\n",
      "{'input_ids': tensor([[50257,   383,  3807,   373,  1049,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
       "            <style>\n",
       "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
       "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
       "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
       "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
       "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
       "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2)); color: black; }\n",
       "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
       "                .token:hover .tooltip { display: block; }\n",
       "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
       "            </style>\n",
       "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
       "            <div id=\"demonstration-container\">\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.174</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.181</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.180</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.165</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.153</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.148</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "from IPython.display import HTML, display\n",
    "from jinja2 import Template\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    return [token.lstrip('Ġ') for token in tokens if len(token.lstrip('Ġ')) != 0]\n",
    "\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    X_TO_Y = \"X->Y->theta\"\n",
    "    Y_TO_X = \"Y->X->theta\"\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 1\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        # Add one concept token for each task\n",
    "        new_tokens = [f\"<{task}_concept>\" for task in tasks]\n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        # Initialize new token embeddings with the mean of pre-trained embeddings\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        new_token_ids = [self.tokenizer.convert_tokens_to_ids(token) for token in new_tokens]\n",
    "        with torch.no_grad():\n",
    "            mean_embedding = embed_layer.weight.mean(dim=0)\n",
    "            for token_id in new_token_ids:\n",
    "                embed_layer.weight[token_id] = mean_embedding\n",
    "\n",
    "        return new_tokens\n",
    "\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "\n",
    "        optimizer = AdamW([{'params': embed_layer.weight, 'lr': self.config.learning_rate}])\n",
    "        new_token_ids = torch.tensor(\n",
    "            [self.tokenizer.convert_tokens_to_ids(token) for token in concept_tokens],\n",
    "            device=self.config.device\n",
    "        )\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "\n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item,  concept_tokens, direction)\n",
    "                total_loss += loss / len(batch)\n",
    "            \n",
    "            total_loss.backward()\n",
    "\n",
    "            # Regularize attention to prevent concept token dominance\n",
    "            with torch.no_grad():\n",
    "                attention_weights = embed_layer.weight.grad[new_token_ids]\n",
    "                attention_weights = torch.clamp(attention_weights, max=0.1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 200 == 0:\n",
    "                print(f\"Step {step}, Loss: {total_loss.item()}\")\n",
    "    def _compute_batch_loss(self, item: Dict, concept_tokens: List[str], direction: CausalDirection) -> torch.Tensor:\n",
    "        \n",
    "        concept_token = concept_tokens[0]  # Only one token for the sentiment task\n",
    "\n",
    "        # Sequence construction\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            sequence = f\"{concept_token} {item['text']} {item['label']} {self.tokenizer.eos_token}\"\n",
    "        else:\n",
    "            sequence = f\"{concept_token} {item['label']} {item['text']} {self.tokenizer.eos_token}\"\n",
    "\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        target_ids = inputs[\"input_ids\"]\n",
    "\n",
    "        outputs = self.model(**inputs)\n",
    "        shift_logits = outputs.logits[..., :-1, :]\n",
    "        shift_labels = target_ids[..., 1:]\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        return loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "    def compute_token_contributions(self, text: str, concept_tokens: List[str]) -> List[Dict]:\n",
    "        # Combine concept tokens with the input text\n",
    "        sequence = f\"{' '.join(concept_tokens)} {text}\"\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "\n",
    "\n",
    "        print(sequence)\n",
    "        print(inputs)\n",
    "        # Obtain embeddings for input tokens and enable gradient computation\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        input_embeddings = embed_layer(inputs[\"input_ids\"]).clone().detach().requires_grad_(True)\n",
    "\n",
    "        # Forward pass using embeddings\n",
    "        outputs = self.model(inputs_embeds=input_embeddings, output_attentions=True, output_hidden_states=True)\n",
    "        attentions = outputs.attentions  # Attention weights from the model\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute gradient of logits with respect to embeddings\n",
    "        logits_sum = logits.sum()  # Sum over all logits\n",
    "        token_grads = torch.autograd.grad(outputs=logits_sum, inputs=input_embeddings, retain_graph=True)[0]\n",
    "\n",
    "        # Combine contributions across all layers\n",
    "        layer_contributions = []\n",
    "        for layer_attention in attentions:\n",
    "            avg_attention = layer_attention.mean(dim=1)  # Average over heads\n",
    "            layer_contributions.append(avg_attention * token_grads.norm(dim=-1))  # Combine attention and gradient norms\n",
    "\n",
    "        # Average contributions across layers\n",
    "        combined_contributions = torch.stack(layer_contributions).mean(dim=0)  # Average over layers\n",
    "        contributions = combined_contributions.sum(dim=-1).detach().cpu().numpy()  # Sum contributions per token\n",
    "\n",
    "        # Normalize contributions\n",
    "        contributions /= contributions.sum()\n",
    "\n",
    "        # Map tokens to contributions\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "\n",
    "        tokens = clean_tokens(tokens)\n",
    "        return [{\"token\": token, \"score\": contribution} for token, contribution in zip(tokens, contributions[0])]\n",
    "\n",
    "class DashboardVisualizer:\n",
    "    def __init__(self, demonstration_scores):\n",
    "        self.demonstration_scores = demonstration_scores\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        html_template = '''\n",
    "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
    "            <style>\n",
    "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
    "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
    "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
    "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
    "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
    "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2)); color: black; }\n",
    "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
    "                .token:hover .tooltip { display: block; }\n",
    "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
    "            </style>\n",
    "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
    "            <div id=\"demonstration-container\">\n",
    "                {% for demo in demonstration_scores %}\n",
    "                <div class=\"demonstration-card\">\n",
    "                    <div class=\"demonstration-header\">Demonstration Score: {{ \"%.3f\"|format(demo.score) }}</div>\n",
    "                    <div>\n",
    "                        <b>Token Contributions:</b>\n",
    "                        <div class=\"token-container\">\n",
    "                            {% for token in demo.token_contributions %}\n",
    "                            <div class=\"token\" style=\"--score: {{ token.score }}\" data-score=\"{{ token.score }}\">\n",
    "                                {{ token.token }}\n",
    "                                <span class=\"tooltip\">Score: {{ \"%.2f\"|format(token.score) }}</span>\n",
    "                            </div>\n",
    "                            {% endfor %}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        template = Template(html_template)\n",
    "        rendered_html = template.render(demonstration_scores=self.demonstration_scores)\n",
    "        display(HTML(rendered_html))\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "set_global_seed(42)\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=5)\n",
    "concept_learner = ConceptLearner(config)\n",
    "\n",
    "train_data = [\n",
    "    {\"text\": \"The movie was great.\", \"label\": \"positive\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The book was boring.\", \"label\": \"negative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The article explained AI clearly.\", \"label\": \"informative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The novel was thrilling.\", \"label\": \"exciting\", \"task\": \"sentiment\"}\n",
    "]\n",
    "\n",
    "tasks = [\"sentiment\"]\n",
    "concept_learner.train_concept_tokens(train_data, tasks, direction=CausalDirection.X_TO_Y)\n",
    "\n",
    "test_text = \"The movie was great.\"\n",
    "concept_tokens = concept_learner.add_concept_tokens(tasks)\n",
    "contributions = concept_learner.compute_token_contributions(test_text, concept_tokens)\n",
    "\n",
    "\n",
    "vis = DashboardVisualizer(contributions)\n",
    "vis.create_dashboard()\n",
    "# for c in contributions:\n",
    "#     print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 8.226791381835938\n",
      "Step 200, Loss: 0.8427249789237976\n",
      "Step 400, Loss: 0.23415812849998474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
       "            <style>\n",
       "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
       "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
       "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
       "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
       "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
       "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score))); color: black; }\n",
       "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
       "                .token:hover .tooltip { display: block; }\n",
       "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
       "            </style>\n",
       "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
       "            <div id=\"demonstration-container\">\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">The article was clear.</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 1.0\" data-score=\"1.0\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.19</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.9125672\" data-score=\"0.9125672\">\n",
       "                                article\n",
       "                                <span class=\"tooltip\">Score: 0.18</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.7954977\" data-score=\"0.7954977\">\n",
       "                                was\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.70517\" data-score=\"0.70517\">\n",
       "                                clear\n",
       "                                <span class=\"tooltip\">Score: 0.15</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.66333514\" data-score=\"0.66333514\">\n",
       "                                .\n",
       "                                <span class=\"tooltip\">Score: 0.15</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.67231923\" data-score=\"0.67231923\">\n",
       "                                <sentiment_concept>\n",
       "                                <span class=\"tooltip\">Score: 0.15</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">The book was dull.</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 1.0\" data-score=\"1.0\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.19</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.9491357\" data-score=\"0.9491357\">\n",
       "                                book\n",
       "                                <span class=\"tooltip\">Score: 0.18</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.83234406\" data-score=\"0.83234406\">\n",
       "                                was\n",
       "                                <span class=\"tooltip\">Score: 0.17</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.7659361\" data-score=\"0.7659361\">\n",
       "                                dull\n",
       "                                <span class=\"tooltip\">Score: 0.16</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.71625304\" data-score=\"0.71625304\">\n",
       "                                .\n",
       "                                <span class=\"tooltip\">Score: 0.15</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.73530054\" data-score=\"0.73530054\">\n",
       "                                <sentiment_concept>\n",
       "                                <span class=\"tooltip\">Score: 0.15</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from jinja2 import Template\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "def clean_tokens(tokens):\n",
    "    return [token.lstrip('Ġ') for token in tokens if len(token.lstrip('Ġ')) != 0]\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 1\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 1000\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        # Add one concept token per task\n",
    "        new_tokens = [f\"<{task}_concept>\" for task in tasks]\n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        # Initialize new token embeddings\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        new_token_ids = [self.tokenizer.convert_tokens_to_ids(token) for token in new_tokens]\n",
    "        with torch.no_grad():\n",
    "            mean_embedding = embed_layer.weight.mean(dim=0)\n",
    "            for token_id in new_token_ids:\n",
    "                embed_layer.weight[token_id] = mean_embedding\n",
    "\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        # Add semantic concept tokens\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "\n",
    "        # Optimizer to update concept token embeddings\n",
    "        optimizer = AdamW([{'params': embed_layer.weight, 'lr': self.config.learning_rate}])\n",
    "        new_token_ids = torch.tensor(\n",
    "            [self.tokenizer.convert_tokens_to_ids(token) for token in concept_tokens],\n",
    "            device=self.config.device\n",
    "        )\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            # Create a batch\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "\n",
    "            # Compute the batch loss\n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item, concept_tokens, direction)\n",
    "                total_loss += loss / len(batch)\n",
    "            \n",
    "            # Backpropagate the loss\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Regularize gradients for concept token embeddings\n",
    "            with torch.no_grad():\n",
    "                concept_grads = embed_layer.weight.grad[new_token_ids]\n",
    "                concept_grad_norms = concept_grads.norm(dim=-1, keepdim=True)\n",
    "                embed_layer.weight.grad[new_token_ids] /= concept_grad_norms.clamp(min=1e-8)  # Normalize gradients\n",
    "\n",
    "            # Step the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log progress\n",
    "            if step % 200 == 0:\n",
    "                print(f\"Step {step}, Loss: {total_loss.item()}\")\n",
    "    \n",
    "    def _compute_batch_loss(self, item: Dict, concept_tokens: List[str], direction: CausalDirection) -> torch.Tensor:\n",
    "        # Use the first concept token for the task\n",
    "        concept_token = concept_tokens[0]\n",
    "\n",
    "        # Construct sequence based on the direction\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            sequence = f\"{concept_token} {item['text']} {item['label']} {self.tokenizer.eos_token}\"\n",
    "        else:\n",
    "            sequence = f\"{concept_token} {item['label']} {item['text']} {self.tokenizer.eos_token}\"\n",
    "\n",
    "        # Tokenize the sequence\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        target_ids = inputs[\"input_ids\"]\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = self.model(**inputs)\n",
    "        shift_logits = outputs.logits[..., :-1, :]\n",
    "        shift_labels = target_ids[..., 1:]\n",
    "\n",
    "        # Compute the language modeling loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        return loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "    def compute_token_contributions(self, sequence: str) -> List[Dict]:\n",
    "        inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "        embed_layer = self.model.get_input_embeddings()\n",
    "        input_embeddings = embed_layer(inputs[\"input_ids\"]).clone().detach().requires_grad_(True)\n",
    "\n",
    "        # Forward pass with embeddings\n",
    "        outputs = self.model(inputs_embeds=input_embeddings, output_attentions=True, output_hidden_states=True)\n",
    "        attentions = outputs.attentions\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute gradient of logits with respect to embeddings\n",
    "        logits_sum = logits.sum()\n",
    "        token_grads = torch.autograd.grad(outputs=logits_sum, inputs=input_embeddings, retain_graph=True)[0]\n",
    "\n",
    "        # Combine contributions\n",
    "        layer_contributions = []\n",
    "        for layer_attention in attentions:\n",
    "            avg_attention = layer_attention.mean(dim=1)  # Average over heads\n",
    "            layer_contributions.append(avg_attention * token_grads.norm(dim=-1))\n",
    "\n",
    "        combined_contributions = torch.stack(layer_contributions).mean(dim=0)  # Average across layers\n",
    "        contributions = combined_contributions.sum(dim=-1).detach().cpu().numpy()\n",
    "        contributions /= contributions.sum()\n",
    "\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "\n",
    "        tokens = clean_tokens(tokens)\n",
    "        # print(tokens)\n",
    "        # cleaned_tokens = [token.lstrip(\"Ġ\") for token in tokens]\n",
    "\n",
    "        return [{\"token\": token, \"score\": contribution} for token, contribution in zip(tokens, contributions[0])]\n",
    "\n",
    "    def score_demonstrations(self, pool: List[Dict], concept_token: str, test_input: str) -> List[Dict]:\n",
    "        scores = []\n",
    "        for demo in pool:\n",
    "            sequence = f\"{concept_token} {demo['text']} {demo['label']} {self.tokenizer.eos_token}\"\n",
    "            inputs = self.tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=self.config.max_length).to(self.config.device)\n",
    "            embed_layer = self.model.get_input_embeddings()\n",
    "            input_embeddings = embed_layer(inputs[\"input_ids\"]).clone().detach().requires_grad_(True)\n",
    "\n",
    "            outputs = self.model(inputs_embeds=input_embeddings, output_attentions=True)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Compute score as gradient norm\n",
    "            logits_sum = logits.sum()\n",
    "            token_grads = torch.autograd.grad(outputs=logits_sum, inputs=input_embeddings, retain_graph=True)[0]\n",
    "            demo_score = token_grads.norm(dim=-1).sum().item()\n",
    "            scores.append({\"demo\": demo, \"score\": demo_score})\n",
    "        # Normalize scores across the entire pool\n",
    "        total_score = sum(score[\"score\"] for score in scores)\n",
    "        for score in scores:\n",
    "            score[\"score\"] /= total_score\n",
    "\n",
    "        return sorted(scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    def select_top_k_demonstrations(self, pool: List[Dict], concept_token: str, test_input: str, k: int) -> List[Dict]:\n",
    "        scored_demos = self.score_demonstrations(pool, concept_token, test_input)\n",
    "        return scored_demos[:k]\n",
    "    \n",
    "class DashboardVisualizer:\n",
    "    def __init__(self, demonstration_scores):\n",
    "        self.demonstration_scores = demonstration_scores\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        html_template = '''\n",
    "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
    "            <style>\n",
    "                .section-title { font-weight: bold; margin: 10px 0; color: #2c5282; font-size: 20px; }\n",
    "                .demonstration-card { margin: 10px 0; padding: 15px; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #ddd; }\n",
    "                .demonstration-header { font-size: 16px; font-weight: bold; color: #2c5282; margin-bottom: 10px; }\n",
    "                .token-container { margin-top: 10px; display: flex; flex-wrap: wrap; }\n",
    "                .token { display: inline-block; margin: 5px; padding: 5px 8px; border-radius: 4px; font-size: 14px; position: relative; cursor: pointer; background-color: rgb(255, 255, 255); }\n",
    "                .token[data-score] { background-color: rgba(255, 69, 0, calc(var(--score))); color: black; }\n",
    "                .token:hover { background-color: rgba(255, 0, 0, 1); }\n",
    "                .token:hover .tooltip { display: block; }\n",
    "                .tooltip { display: none; position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background-color: #333; color: white; padding: 5px 8px; border-radius: 4px; font-size: 12px; z-index: 10; }\n",
    "            </style>\n",
    "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
    "            <div id=\"demonstration-container\">\n",
    "                {% for demo in demonstration_scores %}\n",
    "                <div class=\"demonstration-card\">\n",
    "                    <div class=\"demonstration-header\">{{ demo.demo.text }}</div>\n",
    "                    <div>\n",
    "                        <b>Token Contributions:</b>\n",
    "                        <div class=\"token-container\">\n",
    "                            {% for token in demo.token_contributions %}\n",
    "                            <div class=\"token\" style=\"--score: {{ token.scaled_score }}\" data-score=\"{{ token.scaled_score }}\">\n",
    "                                {{ token.token }}\n",
    "                                <span class=\"tooltip\">Score: {{ \"%.2f\"|format(token.score) }}</span>\n",
    "                            </div>\n",
    "                            {% endfor %}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        template = Template(html_template)\n",
    "        rendered_html = template.render(demonstration_scores=self.demonstration_scores)\n",
    "        display(HTML(rendered_html))\n",
    "\n",
    "# Main Execution\n",
    "set_global_seed(42)\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=1, num_train_steps=500, learning_rate=1e-4)\n",
    "concept_learner = ConceptLearner(config)\n",
    "\n",
    "# Demonstration pool\n",
    "demonstration_pool = [\n",
    "    {\"text\": \"The movie was fantastic.\", \"label\": \"positive\"},\n",
    "    {\"text\": \"The book was dull.\", \"label\": \"negative\"},\n",
    "    {\"text\": \"The article was clear.\", \"label\": \"informative\"},\n",
    "    {\"text\": \"The game was thrilling.\", \"label\": \"exciting\"}\n",
    "]\n",
    "\n",
    "# Training data (example)\n",
    "train_data = [\n",
    "    {\"text\": \"The movie was thrilling.\", \"label\": \"positive\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The book was boring.\", \"label\": \"negative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The article explained AI well.\", \"label\": \"informative\", \"task\": \"sentiment\"},\n",
    "    {\"text\": \"The match was exciting.\", \"label\": \"exciting\", \"task\": \"sentiment\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Test input\n",
    "test_input = \"The movie was great.\"\n",
    "# Add concept tokens\n",
    "concept_tokens = concept_learner.add_concept_tokens([\"sentiment\"])\n",
    "\n",
    "# Train the model on the concept tokens\n",
    "concept_learner.train_concept_tokens(train_data, tasks=[\"sentiment\"], direction=CausalDirection.X_TO_Y)\n",
    "\n",
    "# Select top-K demonstrations\n",
    "top_k_demos = concept_learner.select_top_k_demonstrations(demonstration_pool, concept_tokens[0], test_input, k=2)\n",
    "\n",
    "# Prepare `top_k_demos` for visualization\n",
    "for demo in top_k_demos:\n",
    "    # Extract text from the nested \"demo\" dictionary\n",
    "    text = demo[\"demo\"][\"text\"]\n",
    "\n",
    "    # Construct the sequence with the test input and compute contributions\n",
    "    sequence = f\"{concept_tokens[0]} {text} {concept_tokens[0]} {test_input} {concept_learner.tokenizer.eos_token}\"\n",
    "    token_contributions = concept_learner.compute_token_contributions(sequence)\n",
    "\n",
    "    # Tokenize the full sequence to locate the demonstration text\n",
    "    tokenized_sequence = concept_learner.tokenizer(sequence, return_tensors=\"pt\", truncation=True)[\"input_ids\"][0]\n",
    "    tokens = concept_learner.tokenizer.convert_ids_to_tokens(tokenized_sequence)\n",
    "\n",
    "    # Find tokens between the first and second `<sentiment_concept>` markers\n",
    "    start_idx = tokens.index(\"<sentiment_concept>\") + 1\n",
    "    end_idx = tokens.index(\"<sentiment_concept>\", start_idx) - 1\n",
    "\n",
    "    # Filter contributions to include only tokens between the markers\n",
    "    filtered_contributions = token_contributions[start_idx:end_idx]\n",
    "\n",
    "    # Normalize token scores\n",
    "    total_score = sum(contrib[\"score\"] for contrib in filtered_contributions)\n",
    "    for contrib in filtered_contributions:\n",
    "        contrib[\"score\"] /= total_score\n",
    "\n",
    "    # Enhance and scale token contributions for better visualization\n",
    "    raw_scores = np.array([contrib[\"score\"] for contrib in filtered_contributions])\n",
    "    scaled_scores = (raw_scores**2) / (raw_scores**2).max()  # Quadratic scaling\n",
    "    scaled_scores = 0.2 + 0.8 * scaled_scores  # Map to range [0.2, 1]\n",
    "\n",
    "    for contrib, scaled_score in zip(filtered_contributions, scaled_scores):\n",
    "        contrib[\"scaled_score\"] = scaled_score\n",
    "\n",
    "    # Update `demo` to only include text and filtered, normalized, scaled token contributions\n",
    "    demo[\"demo\"] = {\"text\": text}\n",
    "    demo[\"token_contributions\"] = filtered_contributions\n",
    "\n",
    "# Visualize\n",
    "visualizer = DashboardVisualizer(demonstration_scores=top_k_demos)\n",
    "visualizer.create_dashboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'demo': {'text': 'The article was clear.'},\n",
       "  'score': 0.28238546668095915,\n",
       "  'token_contributions': [{'token': 'The',\n",
       "    'score': np.float32(0.18388858),\n",
       "    'scaled_score': np.float32(1.0)},\n",
       "   {'token': 'article',\n",
       "    'score': np.float32(0.18083894),\n",
       "    'scaled_score': np.float32(0.9736853)},\n",
       "   {'token': 'was',\n",
       "    'score': np.float32(0.16619962),\n",
       "    'scaled_score': np.float32(0.8534924)},\n",
       "   {'token': 'clear',\n",
       "    'score': np.float32(0.15695323),\n",
       "    'scaled_score': np.float32(0.7828019)},\n",
       "   {'token': '.',\n",
       "    'score': np.float32(0.15534891),\n",
       "    'scaled_score': np.float32(0.7709484)},\n",
       "   {'token': '<sentiment_concept>',\n",
       "    'score': np.float32(0.15677066),\n",
       "    'scaled_score': np.float32(0.7814468)}]},\n",
       " {'demo': {'text': 'The book was dull.'},\n",
       "  'score': 0.24516247983923464,\n",
       "  'token_contributions': [{'token': 'The',\n",
       "    'score': np.float32(0.18041803),\n",
       "    'scaled_score': np.float32(1.0)},\n",
       "   {'token': 'book',\n",
       "    'score': np.float32(0.17398524),\n",
       "    'scaled_score': np.float32(0.94396913)},\n",
       "   {'token': 'was',\n",
       "    'score': np.float32(0.1614347),\n",
       "    'scaled_score': np.float32(0.8405069)},\n",
       "   {'token': 'dull',\n",
       "    'score': np.float32(0.16481313),\n",
       "    'scaled_score': np.float32(0.86759603)},\n",
       "   {'token': '.',\n",
       "    'score': np.float32(0.1609984),\n",
       "    'scaled_score': np.float32(0.8370496)},\n",
       "   {'token': '<sentiment_concept>',\n",
       "    'score': np.float32(0.15835051),\n",
       "    'scaled_score': np.float32(0.81626713)}]}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': '<sentiment_concept>', 'score': np.float32(0.071037024)},\n",
       " {'token': 'The',\n",
       "  'score': np.float32(0.20560512),\n",
       "  'scaled_score': np.float32(0.85421455)},\n",
       " {'token': 'book',\n",
       "  'score': np.float32(0.19827428),\n",
       "  'scaled_score': np.float32(0.80839425)},\n",
       " {'token': 'was',\n",
       "  'score': np.float32(0.18397163),\n",
       "  'scaled_score': np.float32(0.7237862)},\n",
       " {'token': 'dull', 'score': np.float32(0.06638897)},\n",
       " {'token': '.', 'score': np.float32(0.06485235)},\n",
       " {'token': '<sentiment_concept>', 'score': np.float32(0.06378574)},\n",
       " {'token': 'The',\n",
       "  'score': np.float32(0.2273625),\n",
       "  'scaled_score': np.float32(1.0)},\n",
       " {'token': 'movie', 'score': np.float32(0.07399508)},\n",
       " {'token': 'was',\n",
       "  'score': np.float32(0.18478644),\n",
       "  'scaled_score': np.float32(0.7284362)},\n",
       " {'token': 'great', 'score': np.float32(0.059997387)},\n",
       " {'token': '.', 'score': np.float32(0.05712551)},\n",
       " {'token': '<|endoftext|>', 'score': np.float32(0.0629154)}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'demo': {'text': 'The article was clear.'},\n",
       "  'score': 0.28238546668095915,\n",
       "  'token_contributions': [{'token': '<sentiment_concept>',\n",
       "    'score': np.float32(0.07184701)},\n",
       "   {'token': 'The', 'score': np.float32(0.074176975)},\n",
       "   {'token': 'article', 'score': np.float32(0.07294681)},\n",
       "   {'token': 'was', 'score': np.float32(0.0670416)},\n",
       "   {'token': 'clear', 'score': np.float32(0.06331179)},\n",
       "   {'token': '.', 'score': np.float32(0.06266464)},\n",
       "   {'token': '<sentiment_concept>', 'score': np.float32(0.063238144)},\n",
       "   {'token': 'The', 'score': np.float32(0.081818275)},\n",
       "   {'token': 'movie', 'score': np.float32(0.076012485)},\n",
       "   {'token': 'was', 'score': np.float32(0.06556139)},\n",
       "   {'token': 'great', 'score': np.float32(0.057296697)},\n",
       "   {'token': '.', 'score': np.float32(0.056295212)},\n",
       "   {'token': '<|endoftext|>', 'score': np.float32(0.059941214)}]},\n",
       " {'demo': {'text': 'The book was dull.'},\n",
       "  'score': 0.24516247983923464,\n",
       "  'token_contributions': [{'token': '<sentiment_concept>',\n",
       "    'score': np.float32(0.071037024)},\n",
       "   {'token': 'The', 'score': np.float32(0.07267484)},\n",
       "   {'token': 'book', 'score': np.float32(0.070083626)},\n",
       "   {'token': 'was', 'score': np.float32(0.065028094)},\n",
       "   {'token': 'dull', 'score': np.float32(0.06638897)},\n",
       "   {'token': '.', 'score': np.float32(0.06485235)},\n",
       "   {'token': '<sentiment_concept>', 'score': np.float32(0.06378574)},\n",
       "   {'token': 'The', 'score': np.float32(0.08036538)},\n",
       "   {'token': 'movie', 'score': np.float32(0.07399508)},\n",
       "   {'token': 'was', 'score': np.float32(0.0653161)},\n",
       "   {'token': 'great', 'score': np.float32(0.059997387)},\n",
       "   {'token': '.', 'score': np.float32(0.05712551)},\n",
       "   {'token': '<|endoftext|>', 'score': np.float32(0.0629154)}]}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"movie was great\"\n",
    "inputs = concept_learner.tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = concept_learner.model(**inputs)\n",
    "attentions = outputs.attentions  # List of attention tensors (num_layers, batch, num_heads, seq_len, seq_len)\n",
    "input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "tokens = concept_learner.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# Initialize cumulative token contributions\n",
    "num_layers = len(attentions)\n",
    "token_contributions = torch.zeros(input_ids.size(0))\n",
    "\n",
    "# Weighted sum of contributions across layers\n",
    "layer_weights = torch.linspace(0.1, 1.0, steps=num_layers)\n",
    "for layer_idx, layer_attention in enumerate(attentions):\n",
    "    # Average attention over heads\n",
    "    avg_attention = layer_attention.mean(dim=1)  # (batch, seq_len, seq_len)\n",
    "\n",
    "    # Sum contributions for each token\n",
    "    token_scores = avg_attention.sum(dim=1)  # (batch, seq_len)\n",
    "    normalized_scores = token_scores / token_scores.sum(dim=1, keepdim=True)  # Normalize by sequence\n",
    "\n",
    "    # Weighted by layer importance\n",
    "    token_contributions += layer_weights[layer_idx] * normalized_scores.squeeze(0)\n",
    "\n",
    "# Normalize contributions to sum to 1\n",
    "token_contributions /= token_contributions.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9054, 0.0742, 0.0204], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions[0].mean(dim=1).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = concept_learner.compute_token_contributions(test_text)\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.config.device)\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        attentions = outputs.attentions\n",
    "        layer_contributions = [\n",
    "            layer_att.mean(dim=1).sum(dim=2)\n",
    "            for layer_att in attentions\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihongxuan/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 new tokens.\n",
      "Resized token embeddings to 50267 tokens.\n",
      "Some new concept token embeddings are identical. Please check the token addition process.\n",
      "Initial concept token embeddings (first 5 tokens):\n",
      "tensor([[-0.0025, -0.0585,  0.1174,  ...,  0.0236,  0.0039,  0.0344],\n",
      "        [-0.0025, -0.0585,  0.1174,  ...,  0.0236,  0.0039,  0.0344],\n",
      "        [-0.0025, -0.0585,  0.1174,  ...,  0.0236,  0.0039,  0.0344],\n",
      "        [-0.0025, -0.0585,  0.1174,  ...,  0.0236,  0.0039,  0.0344],\n",
      "        [-0.0025, -0.0585,  0.1174,  ...,  0.0236,  0.0039,  0.0344]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing examples: 100%|██████████| 5/5 [00:00<00:00, 1818.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 1/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 0: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 2/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 1: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 3/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 2: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 4/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 3: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 5/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 4: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 6/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 5: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 7/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 6: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 8/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 7: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 9/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 8: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 10/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 9: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 11/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 10: torch.Size([768, 2304]), expected (2304, 768)\n",
      "Processing layer 12/12\n",
      "W_attn shape: torch.Size([768, 2304])\n",
      "Unexpected W_attn shape in layer 11: torch.Size([768, 2304]), expected (2304, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing examples: 100%|██████████| 5/5 [00:00<00:00, 29.36it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SemanticICLFramework:\n",
    "    def __init__(self, model_name, examples, tau=1.0, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the framework with a model and predefined examples.\n",
    "\n",
    "        Parameters:\n",
    "            model_name (str): The Hugging Face model name.\n",
    "            examples (List[Dict]): A list of examples, each containing 'text' and 'triplets'.\n",
    "            tau (float): Threshold for strong attention focus.\n",
    "            device (str): Device to run the model on ('cpu' or 'cuda'). Defaults to GPU if available.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.examples = examples\n",
    "        self.tau = tau\n",
    "\n",
    "        # Set device\n",
    "        if device:\n",
    "            self.device = torch.device(device)\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Add new concept tokens\n",
    "        self.add_concept_tokens()\n",
    "\n",
    "    def add_concept_tokens(self):\n",
    "        \"\"\"\n",
    "        Add new concept tokens to the tokenizer and resize model embeddings.\n",
    "        \"\"\"\n",
    "        # Define new concept tokens\n",
    "        self.new_concept_tokens = [f\"[CONCEPT{i}]\" for i in range(1, 11)]  # [CONCEPT1], [CONCEPT2], ..., [CONCEPT10]\n",
    "\n",
    "        # Add new tokens to the tokenizer\n",
    "        num_added_tokens = self.tokenizer.add_tokens(self.new_concept_tokens)\n",
    "        print(f\"Added {num_added_tokens} new tokens.\")\n",
    "\n",
    "        # Resize the model's embeddings to accommodate new tokens\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        print(f\"Resized token embeddings to {len(self.tokenizer)} tokens.\")\n",
    "\n",
    "        # Verify unique embeddings\n",
    "        self.verify_unique_embeddings()\n",
    "\n",
    "    def verify_unique_embeddings(self):\n",
    "        \"\"\"\n",
    "        Verify that each new concept token has a unique embedding.\n",
    "        \"\"\"\n",
    "        # Access the token embeddings\n",
    "        token_embeddings = self.model.get_input_embeddings().weight.data  # Shape: [vocab_size, hidden_size]\n",
    "\n",
    "        # Get the indices of the new tokens\n",
    "        new_token_ids = self.tokenizer.convert_tokens_to_ids(self.new_concept_tokens)\n",
    "\n",
    "        # Extract the embeddings for the new tokens\n",
    "        new_token_embeddings = token_embeddings[new_token_ids]\n",
    "\n",
    "        # Check for uniqueness\n",
    "        uniqueness = (new_token_embeddings[0] != new_token_embeddings[1:]).any(dim=1)\n",
    "        if uniqueness.all():\n",
    "            print(\"All new concept token embeddings are unique.\")\n",
    "        else:\n",
    "            print(\"Some new concept token embeddings are identical. Please check the token addition process.\")\n",
    "\n",
    "        # Optional: Print the first 5 embeddings\n",
    "        print(\"Initial concept token embeddings (first 5 tokens):\")\n",
    "        print(new_token_embeddings[:5])\n",
    "\n",
    "    def preprocess_examples(self):\n",
    "        \"\"\"\n",
    "        Preprocess the examples by tokenizing text and preparing triplets.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: A list of processed examples with tokenized inputs and triplets.\n",
    "        \"\"\"\n",
    "        processed = []\n",
    "        for example in tqdm(self.examples, desc=\"Preprocessing examples\"):\n",
    "            tokens = self.tokenizer(\n",
    "                example[\"text\"],\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            triplets = example[\"triplets\"]\n",
    "            processed.append({\n",
    "                \"text\": example[\"text\"],\n",
    "                \"tokens\": tokens,\n",
    "                \"triplets\": triplets\n",
    "            })\n",
    "        return processed\n",
    "\n",
    "    def analyze_attention_heads(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Analyze attention heads to retrieve attention matrices.\n",
    "\n",
    "        Parameters:\n",
    "            input_ids (torch.Tensor): Token IDs of the input sequence.\n",
    "            attention_mask (torch.Tensor): Attention mask.\n",
    "\n",
    "        Returns:\n",
    "            List[torch.Tensor]: Attention matrices from each layer.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_attentions=True\n",
    "            )\n",
    "        attentions = outputs.attentions  # List of tensors: one for each layer\n",
    "        return attentions\n",
    "\n",
    "    def get_token_spans(self, input_ids, token):\n",
    "        \"\"\"\n",
    "        Get all spans (start and end indices) of a token in the input_ids.\n",
    "\n",
    "        Parameters:\n",
    "            input_ids (torch.Tensor): Token IDs of the input sequence.\n",
    "            token (str): The token string to search for.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[int, int]]: List of (start, end) indices for the token.\n",
    "        \"\"\"\n",
    "        token_ids = self.tokenizer.encode(token, add_special_tokens=False)\n",
    "        if not token_ids:\n",
    "            return []\n",
    "\n",
    "        spans = []\n",
    "        token_length = len(token_ids)\n",
    "        input_length = input_ids.size(-1)\n",
    "\n",
    "        for i in range(input_length - token_length + 1):\n",
    "            # Compare slices\n",
    "            slice_ids = input_ids[0, i:i+token_length].tolist()\n",
    "            if slice_ids == token_ids:\n",
    "                spans.append((i, i + token_length))\n",
    "        return spans\n",
    "\n",
    "    def detect_induction_heads(self, attentions, triplets, input_ids):\n",
    "        \"\"\"\n",
    "        Detect induction heads that strongly focus on head tokens.\n",
    "\n",
    "        Parameters:\n",
    "            attentions (List[torch.Tensor]): Attention matrices from each layer.\n",
    "            triplets (List[Tuple[str, str, str]]): Extracted triplets.\n",
    "            input_ids (torch.Tensor): Token IDs of the input sequence.\n",
    "\n",
    "        Returns:\n",
    "            dict: Mapping of layer index to list of induction head indices.\n",
    "        \"\"\"\n",
    "        induction_heads_per_layer = {}\n",
    "        for layer_idx, layer_attn in enumerate(attentions):\n",
    "            num_heads = layer_attn.size(1)\n",
    "            induction_heads = []\n",
    "            for head_idx in range(num_heads):\n",
    "                # Average attention over the batch (assuming batch_size=1)\n",
    "                avg_attn = layer_attn[0, head_idx, :, :]  # Shape: [seq_len, seq_len]\n",
    "                for triplet in triplets:\n",
    "                    head_token = triplet[0]\n",
    "                    spans = self.get_token_spans(input_ids, head_token)\n",
    "                    if not spans:\n",
    "                        continue  # Head token not found in input\n",
    "                    for (start, end) in spans:\n",
    "                        # Compute attention scores towards each sub-token of the head token\n",
    "                        attn_scores = avg_attn[:, start:end].mean(dim=-1)  # Shape: [seq_len]\n",
    "                        max_attn = torch.max(attn_scores)\n",
    "                        # Exclude attention to the head token itself when finding other_max\n",
    "                        # Assuming that the head token can attend to itself\n",
    "                        # To exclude, set those positions to a very low value\n",
    "                        attn_scores_excl = attn_scores.clone()\n",
    "                        attn_scores_excl[start:end] = -float('inf')\n",
    "                        other_max = torch.max(attn_scores_excl)\n",
    "                        if other_max.item() == -float('inf'):\n",
    "                            other_max = 0.0\n",
    "                        if other_max.item() == 0.0:\n",
    "                            ratio = float('inf')  # Avoid division by zero\n",
    "                        else:\n",
    "                            ratio = max_attn / other_max\n",
    "                        if ratio > self.tau:\n",
    "                            induction_heads.append(head_idx)\n",
    "                            break  # Avoid duplicate additions for multiple spans\n",
    "            induction_heads_per_layer[layer_idx] = list(set(induction_heads))\n",
    "        return induction_heads_per_layer\n",
    "\n",
    "    def extract_W_v_W_o(self):\n",
    "        \"\"\"\n",
    "        Extract W_v and W_o matrices from the model for all layers.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[torch.Tensor, torch.Tensor]]: List of (W_v, W_o) for each layer.\n",
    "        \"\"\"\n",
    "        W_v_W_o_per_layer = []\n",
    "        for layer_idx, layer in enumerate(self.model.transformer.h):\n",
    "            print(f\"Processing layer {layer_idx + 1}/{self.model.config.num_hidden_layers}\")\n",
    "            # Each layer has c_attn and c_proj\n",
    "            c_attn = layer.attn.c_attn  # Linear layer for Q, K, V\n",
    "            c_proj = layer.attn.c_proj  # Output projection\n",
    "            W_attn = c_attn.weight.data  # Shape: [3 * hidden_size, hidden_size]\n",
    "            print(f\"W_attn shape: {W_attn.shape}\")\n",
    "\n",
    "            hidden_size = self.model.config.hidden_size\n",
    "            num_heads = self.model.config.num_attention_heads\n",
    "            head_dim = hidden_size // num_heads\n",
    "\n",
    "            # Validate W_attn shape\n",
    "            expected_W_attn_shape = (3 * hidden_size, hidden_size)\n",
    "            if W_attn.shape != expected_W_attn_shape:\n",
    "                print(f\"Unexpected W_attn shape in layer {layer_idx}: {W_attn.shape}, expected {expected_W_attn_shape}\")\n",
    "                W_v_W_o_per_layer.append((torch.zeros(num_heads, head_dim, hidden_size).to(self.device), torch.zeros_like(c_proj.weight.data)))\n",
    "                continue\n",
    "\n",
    "            # Split W_attn into W_q, W_k, W_v\n",
    "            W_q = W_attn[:hidden_size, :]\n",
    "            W_k = W_attn[hidden_size:2*hidden_size, :]\n",
    "            W_v = W_attn[2*hidden_size:, :]  # Shape: [hidden_size, hidden_size]\n",
    "            print(f\"W_v shape: {W_v.shape}\")\n",
    "\n",
    "            # Split W_v into per-head W_v\n",
    "            try:\n",
    "                W_v_heads = W_v.view(num_heads, head_dim, hidden_size)  # Shape: [num_heads, head_dim, hidden_size]\n",
    "                print(f\"W_v_heads shape: {W_v_heads.shape}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error reshaping W_v in layer {layer_idx}: {e}\")\n",
    "                W_v_heads = torch.zeros(num_heads, head_dim, hidden_size).to(self.device)\n",
    "\n",
    "            # Store per layer\n",
    "            W_v_W_o_per_layer.append((W_v_heads, c_proj.weight.data))\n",
    "        return W_v_W_o_per_layer\n",
    "\n",
    "    def quantify_influence_on_tail_tokens(self, attentions, induction_heads, triplets, input_ids, W_v_W_o):\n",
    "        \"\"\"\n",
    "        Quantify the influence of induction heads on tail tokens.\n",
    "\n",
    "        Parameters:\n",
    "            attentions (List[torch.Tensor]): Attention matrices from each layer.\n",
    "            induction_heads (dict): Mapping of layer index to list of induction head indices.\n",
    "            triplets (List[Tuple[str, str, str]]): Extracted triplets.\n",
    "            input_ids (torch.Tensor): Token IDs of the input sequence.\n",
    "            W_v_W_o (List[Tuple[torch.Tensor, torch.Tensor]]): List of (W_v, W_o) for each layer.\n",
    "\n",
    "        Returns:\n",
    "            dict: Mapping of layer index to {head index: average relation index}.\n",
    "        \"\"\"\n",
    "        relation_indices_per_layer = {layer: {} for layer in induction_heads}\n",
    "        for layer_idx, heads in induction_heads.items():\n",
    "            W_v_heads, W_o = W_v_W_o[layer_idx]\n",
    "            num_heads = W_v_heads.size(0)\n",
    "            for head_idx in heads:\n",
    "                W_v = W_v_heads[head_idx]  # Shape: [head_dim, hidden_size]\n",
    "                # Compute W_ov for this head: [head_dim, hidden_size] @ [hidden_size, hidden_size] = [head_dim, hidden_size]\n",
    "                W_ov = torch.matmul(W_v, W_o)  # Shape: [head_dim, hidden_size]\n",
    "\n",
    "                # Get attention scores for the specific head\n",
    "                attn_scores = attentions[layer_idx][0, head_idx, :, :]  # Shape: [seq_len, seq_len]\n",
    "                # Apply scaled softmax as per the formulation\n",
    "                scaled_attn = torch.softmax(attn_scores / np.sqrt(self.model.config.hidden_size), dim=-1)  # Shape: [seq_len, seq_len]\n",
    "\n",
    "                for triplet in triplets:\n",
    "                    head_token, relation, tail_token = triplet\n",
    "                    # Tokenize tail_token\n",
    "                    tail_token_ids = self.tokenizer.encode(tail_token, add_special_tokens=False)\n",
    "                    if not tail_token_ids:\n",
    "                        continue  # Skip if tail_token is not found\n",
    "                    tail_token_id = tail_token_ids[0]\n",
    "                    if tail_token_id >= self.model.config.vocab_size:\n",
    "                        continue  # Invalid token ID\n",
    "\n",
    "                    # Compute p_h^{j,t_k}\n",
    "                    # For each token position j, compute p_h^{j,t_k} = softmax(x_j W_ov) [t_k]\n",
    "                    # Since we don't have x_j (hidden states), we'll approximate p_h^{j,t_k} as the attention weights\n",
    "                    # multiplied by W_ov and passed through softmax\n",
    "                    # This is a simplification due to lack of access to intermediate hidden states\n",
    "\n",
    "                    # Compute logits for t_k\n",
    "                    logits = torch.matmul(scaled_attn, W_ov)  # Shape: [seq_len, head_dim]\n",
    "                    # Aggregate head_dim to get a scalar logit per position\n",
    "                    logits = logits.sum(dim=-1)  # Shape: [seq_len]\n",
    "                    p_h = torch.softmax(logits, dim=-1)  # Shape: [seq_len]\n",
    "                    # Identify the position of the head token in the input\n",
    "                    head_token_ids = self.tokenizer.encode(head_token, add_special_tokens=False)\n",
    "                    if not head_token_ids:\n",
    "                        continue\n",
    "                    head_token_id = head_token_ids[0]\n",
    "                    # Find all positions where head_token_id appears\n",
    "                    head_positions = (input_ids == head_token_id).nonzero(as_tuple=True)[0]\n",
    "                    if len(head_positions) == 0:\n",
    "                        continue\n",
    "                    # For simplicity, take the first occurrence\n",
    "                    head_position = head_positions[0].item()\n",
    "                    p_h_tk = p_h[head_position].item()\n",
    "\n",
    "                    # Compute expected p_h over all tokens (mean probability)\n",
    "                    expected_p = p_h.mean().item()\n",
    "\n",
    "                    # Compute q_h^{j,t_k}\n",
    "                    q_h = max(0.0, p_h_tk - expected_p)\n",
    "\n",
    "                    # Compute a_h^j(T)\n",
    "                    sum_q_h = q_h if q_h > 0 else 1e-6  # Avoid division by zero\n",
    "                    a_h = q_h / sum_q_h\n",
    "\n",
    "                    # Aggregate a_h for the specific head\n",
    "                    if head_idx not in relation_indices_per_layer[layer_idx]:\n",
    "                        relation_indices_per_layer[layer_idx][head_idx] = []\n",
    "                    relation_indices_per_layer[layer_idx][head_idx].append(a_h)\n",
    "        return relation_indices_per_layer\n",
    "\n",
    "    def aggregate_relation_indices(self, relation_indices):\n",
    "        \"\"\"\n",
    "        Aggregate the relation indices to determine the importance of each head.\n",
    "\n",
    "        Parameters:\n",
    "            relation_indices (dict): Mapping of layer index to {head index: [indices]}.\n",
    "\n",
    "        Returns:\n",
    "            dict: Mapping of layer index to {head index: average relation index}.\n",
    "        \"\"\"\n",
    "        aggregated = {}\n",
    "        for layer, heads in relation_indices.items():\n",
    "            aggregated[layer] = {}\n",
    "            for head, indices in heads.items():\n",
    "                if indices:\n",
    "                    aggregated[layer][head] = np.mean(indices)\n",
    "                else:\n",
    "                    aggregated[layer][head] = 0\n",
    "        return aggregated\n",
    "\n",
    "    def collect_all_relation_indices(self, processed_examples):\n",
    "        \"\"\"\n",
    "        Process all examples and collect relation indices.\n",
    "\n",
    "        Parameters:\n",
    "            processed_examples (List[Dict]): A list of processed examples.\n",
    "\n",
    "        Returns:\n",
    "            dict: Aggregated relation indices across all examples, structured as {layer: {head: average_relation_index}}\n",
    "        \"\"\"\n",
    "        # Initialize a nested structure to hold sum and count for each head\n",
    "        sum_relation_indices = {}\n",
    "        count_relation_indices = {}\n",
    "\n",
    "        # Extract W_v and W_o for all layers\n",
    "        W_v_W_o = self.extract_W_v_W_o()\n",
    "\n",
    "        for example in tqdm(processed_examples, desc=\"Analyzing examples\"):\n",
    "            tokens = example[\"tokens\"]\n",
    "            input_ids = tokens[\"input_ids\"].to(self.device)\n",
    "            attention_mask = tokens[\"attention_mask\"].to(self.device)\n",
    "            triplets = example[\"triplets\"]\n",
    "\n",
    "            attentions = self.analyze_attention_heads(input_ids, attention_mask)\n",
    "            induction_heads = self.detect_induction_heads(attentions, triplets, input_ids)\n",
    "            relation_indices = self.quantify_influence_on_tail_tokens(attentions, induction_heads, triplets, input_ids, W_v_W_o)\n",
    "\n",
    "            # Aggregate relation indices per head\n",
    "            for layer, heads in relation_indices.items():\n",
    "                if layer not in sum_relation_indices:\n",
    "                    sum_relation_indices[layer] = {}\n",
    "                    count_relation_indices[layer] = {}\n",
    "                for head, a_h in heads.items():\n",
    "                    if head not in sum_relation_indices[layer]:\n",
    "                        sum_relation_indices[layer][head] = 0.0\n",
    "                        count_relation_indices[layer][head] = 0\n",
    "                    sum_relation_indices[layer][head] += a_h\n",
    "                    count_relation_indices[layer][head] += 1\n",
    "\n",
    "        # Compute average relation indices per head\n",
    "        average_relation_indices = {}\n",
    "        for layer in sum_relation_indices:\n",
    "            average_relation_indices[layer] = {}\n",
    "            for head in sum_relation_indices[layer]:\n",
    "                if count_relation_indices[layer][head] > 0:\n",
    "                    average_relation_indices[layer][head] = sum_relation_indices[layer][head] / count_relation_indices[layer][head]\n",
    "                else:\n",
    "                    average_relation_indices[layer][head] = 0\n",
    "\n",
    "        return average_relation_indices\n",
    "\n",
    "    def visualize_heatmap(self, average_relation_indices, num_layers, num_heads):\n",
    "        \"\"\"\n",
    "        Visualize the average relation indices as a heatmap.\n",
    "\n",
    "        Parameters:\n",
    "            average_relation_indices (dict): Mapping of layer index to {head index: average relation index}.\n",
    "            num_layers (int): Total number of layers in the model.\n",
    "            num_heads (int): Total number of attention heads per layer.\n",
    "        \"\"\"\n",
    "        # Initialize a matrix of zeros\n",
    "        heatmap_matrix = np.zeros((num_layers, num_heads))\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            for head in range(num_heads):\n",
    "                if layer in average_relation_indices and head in average_relation_indices[layer]:\n",
    "                    heatmap_matrix[layer, head] = average_relation_indices[layer][head]\n",
    "                else:\n",
    "                    heatmap_matrix[layer, head] = 0\n",
    "\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        sns.heatmap(\n",
    "            heatmap_matrix,\n",
    "            cmap=\"viridis\",\n",
    "            xticklabels=[f\"Head {h}\" for h in range(num_heads)],\n",
    "            yticklabels=[f\"Layer {l}\" for l in range(num_layers)],\n",
    "            cbar_kws={'label': 'Average Relation Index'}\n",
    "        )\n",
    "        plt.xlabel(\"Attention Heads\")\n",
    "        plt.ylabel(\"Layers\")\n",
    "        plt.title(\"Heatmap of Average Relation Index Across Attention Heads and Layers\")\n",
    "        plt.show()\n",
    "\n",
    "    def run_analysis(self):\n",
    "        \"\"\"\n",
    "        Run the full analysis pipeline on all examples and visualize the heatmap.\n",
    "        \"\"\"\n",
    "        processed_examples = self.preprocess_examples()\n",
    "        average_relation_indices = self.collect_all_relation_indices(processed_examples)\n",
    "        # Retrieve model configuration for layers and heads\n",
    "        num_layers = self.model.config.num_hidden_layers\n",
    "        num_heads = self.model.config.num_attention_heads\n",
    "        self.visualize_heatmap(average_relation_indices, num_layers, num_heads)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define simple examples with texts and triplets\n",
    "    examples = [\n",
    "        {\n",
    "            \"text\": \"The pen is used for writing.\",\n",
    "            \"triplets\": [(\"pen\", \"Used-for\", \"writing\")]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"A cat chases a mouse.\",\n",
    "            \"triplets\": [(\"cat\", \"Chases\", \"mouse\")]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The book contains valuable information.\",\n",
    "            \"triplets\": [(\"book\", \"Contains\", \"information\")]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"She uses a laptop for programming.\",\n",
    "            \"triplets\": [(\"laptop\", \"Used-for\", \"programming\")]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The teacher explains the lesson.\",\n",
    "            \"triplets\": [(\"teacher\", \"Explains\", \"lesson\")]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Initialize the framework with the model and examples\n",
    "    framework = SemanticICLFramework(\n",
    "        model_name=\"gpt2\",\n",
    "        examples=examples,\n",
    "        tau=1.0,  # Lowered threshold for induction heads\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    # Run the analysis to generate the heatmap\n",
    "    framework.run_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': 'The', 'score': 0.5053552881033624},\n",
       " {'token': 'movie', 'score': 0.026535969683863625},\n",
       " {'token': 'was', 'score': 0.1988376506866485},\n",
       " {'token': 'great.', 'score': 0.6498844377795232}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'demonstration': 'The article explained AI clearly.',\n",
       "  'label': 'informative'},\n",
       " {'demonstration': 'The novel was thrilling.', 'label': 'exciting'},\n",
       " {'demonstration': 'The movie was great.', 'label': 'positive'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
