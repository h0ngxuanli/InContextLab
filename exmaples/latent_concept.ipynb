{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretability/visualizer.py\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional, Union\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "# Core module for handling latent concept learning and demonstration selection\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class ConceptTokenVisualizer:\n",
    "    \"\"\"\n",
    "    Visualizes learned concept tokens and their relationships\n",
    "    Maps to Figure 5 in the paper\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_learner):\n",
    "        self.concept_learner = concept_learner\n",
    "        self.tsne = TSNE(n_components=2, random_state=42)\n",
    "        \n",
    "    def plot_concept_embeddings(self, tasks: List[str], save_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Create t-SNE visualization of concept token embeddings\n",
    "        Similar to Figure 5 in the paper\n",
    "        \"\"\"\n",
    "        # Get embeddings for all concept tokens\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        \n",
    "        # Extract concept token embeddings\n",
    "        embedding_matrix = self.concept_learner.model.get_input_embeddings().weight\n",
    "        \n",
    "        for task in tasks:\n",
    "            token_ids = self._get_concept_token_ids(task)\n",
    "            task_embeddings = embedding_matrix[token_ids].detach().cpu().numpy()\n",
    "            embeddings.append(task_embeddings)\n",
    "            labels.extend([task] * len(token_ids))\n",
    "            \n",
    "        embeddings = np.vstack(embeddings)\n",
    "        \n",
    "        # Compute t-SNE\n",
    "        tsne_result = self.tsne.fit_transform(embeddings)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(\n",
    "            x=tsne_result[:, 0], \n",
    "            y=tsne_result[:, 1],\n",
    "            hue=labels,\n",
    "            style=labels,\n",
    "            s=100\n",
    "        )\n",
    "        plt.title(\"t-SNE Visualization of Concept Token Embeddings\")\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "    def find_similar_tokens(self, task: str, top_k: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Find most similar vocabulary tokens to concept tokens\n",
    "        Maps to Table 13 in the paper\n",
    "        \"\"\"\n",
    "        concept_embeds = self._get_concept_embeddings(task)\n",
    "        vocab_embeds = self.concept_learner.model.get_input_embeddings().weight\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarities = torch.nn.functional.cosine_similarity(\n",
    "            concept_embeds.unsqueeze(1),\n",
    "            vocab_embeds.unsqueeze(0),\n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        # Get top-k similar tokens for each concept token\n",
    "        top_k_values, top_k_indices = torch.topk(similarities, k=top_k, dim=1)\n",
    "        \n",
    "        results = []\n",
    "        for i, (values, indices) in enumerate(zip(top_k_values, top_k_indices)):\n",
    "            similar_tokens = [\n",
    "                self.concept_learner.tokenizer.decode(idx.item())\n",
    "                for idx in indices\n",
    "            ]\n",
    "            results.append({\n",
    "                'concept_token': f\"{task}_token_{i}\",\n",
    "                'similar_tokens': similar_tokens,\n",
    "                'similarities': values.tolist()\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "\n",
    "class DemonstrationAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes selected demonstrations and their properties\n",
    "    \"\"\"\n",
    "    def __init__(self, demonstration_selector):\n",
    "        self.selector = demonstration_selector\n",
    "        \n",
    "    def plot_score_distribution(self, candidates: List[Dict], task: str):\n",
    "        \"\"\"\n",
    "        Plot histogram of concept token prediction scores\n",
    "        Maps to Figure 10 in the paper\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            if candidate['task'] == task:\n",
    "                score = self.selector._compute_concept_score(candidate)\n",
    "                scores.append(score)\n",
    "                \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(scores, bins=30)\n",
    "        plt.title(f\"Distribution of Concept Scores for {task}\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "        \n",
    "    def analyze_demonstration_diversity(self, demonstrations: List[Dict]):\n",
    "        \"\"\"\n",
    "        Analyze diversity of selected demonstrations\n",
    "        \"\"\"\n",
    "        # Compute embeddings for demonstrations\n",
    "        embeddings = self._get_demonstration_embeddings(demonstrations)\n",
    "        \n",
    "        # Compute pairwise cosine similarities\n",
    "        similarities = torch.nn.functional.cosine_similarity(\n",
    "            embeddings.unsqueeze(1),\n",
    "            embeddings.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'mean_similarity': similarities.mean().item(),\n",
    "            'min_similarity': similarities.min().item(),\n",
    "            'max_similarity': similarities.max().item()\n",
    "        }\n",
    "\n",
    "class PerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes model performance and ablation studies\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics = defaultdict(list)\n",
    "        \n",
    "    def log_experiment(\n",
    "        self,\n",
    "        experiment_name: str,\n",
    "        accuracy: float,\n",
    "        parameters: Dict\n",
    "    ):\n",
    "        \"\"\"Log experimental results\"\"\"\n",
    "        self.metrics[experiment_name].append({\n",
    "            'accuracy': accuracy,\n",
    "            'parameters': parameters\n",
    "        })\n",
    "        \n",
    "    def plot_ablation_study(\n",
    "        self, \n",
    "        parameter: str,\n",
    "        experiments: List[str]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create ablation study plots\n",
    "        Maps to Figure 4 in the paper\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for exp in experiments:\n",
    "            for result in self.metrics[exp]:\n",
    "                data.append({\n",
    "                    'parameter_value': result['parameters'][parameter],\n",
    "                    'accuracy': result['accuracy'],\n",
    "                    'experiment': exp\n",
    "                })\n",
    "                \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(\n",
    "            data=df, \n",
    "            x='parameter_value',\n",
    "            y='accuracy',\n",
    "            hue='experiment'\n",
    "        )\n",
    "        plt.title(f\"Ablation Study: Effect of {parameter}\")\n",
    "        plt.show()\n",
    "        \n",
    "    def compare_causal_directions(\n",
    "        self,\n",
    "        tasks: List[str],\n",
    "        results_xy: Dict[str, float],\n",
    "        results_yx: Dict[str, float]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compare performance between causal directions\n",
    "        Maps to Figure 6 in the paper\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame({\n",
    "            'task': tasks * 2,\n",
    "            'accuracy': list(results_xy.values()) + list(results_yx.values()),\n",
    "            'direction': ['X->Y'] * len(tasks) + ['Y->X'] * len(tasks)\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(data=df, x='task', y='accuracy', hue='direction')\n",
    "        plt.title(\"Performance Comparison: Causal Directions\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    max_length: int = 1024\n",
    "    max_length_per_example: int = 256\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 10000\n",
    "\n",
    "class ConceptLearner:\n",
    "    \"\"\"\n",
    "    Handles latent concept learning phase (Phase 1 from paper)\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(config.model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        \n",
    "    def add_concept_tokens(self, tasks: List[str]) -> None:\n",
    "        \"\"\"Add new concept tokens for each task\"\"\"\n",
    "        new_tokens = []\n",
    "        for task in tasks:\n",
    "            for i in range(self.config.n_prefix_tokens):\n",
    "                new_tokens.append(f\"<{task}_token_{i}>\")\n",
    "        \n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "        # Freeze all parameters except new token embeddings\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.get_input_embeddings().weight.requires_grad = True\n",
    "\n",
    "    def train(self, train_data: List[Dict], task_direction: str = \"X->Y\") -> None:\n",
    "        \"\"\"Train concept tokens\"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [p for p in self.model.parameters() if p.requires_grad],\n",
    "            lr=self.config.learning_rate\n",
    "        )\n",
    "        \n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = self._get_batch(train_data)\n",
    "            loss = self._compute_loss(batch, task_direction)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "class DemonstrationSelector:\n",
    "    \"\"\"\n",
    "    Handles demonstration selection phase (Phase 2 from paper)\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_learner: ConceptLearner):\n",
    "        self.concept_learner = concept_learner\n",
    "        \n",
    "    def select_demonstrations(\n",
    "        self, \n",
    "        candidates: List[Dict],\n",
    "        k: int = 4,\n",
    "        task_direction: str = \"X->Y\"\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Select top-k demonstrations based on concept token prediction probability\"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            score = self._compute_concept_score(candidate, task_direction)\n",
    "            scores.append((score, candidate))\n",
    "            \n",
    "        # Select top-k demonstrations\n",
    "        scores.sort(reverse=True)\n",
    "        return [candidate for _, candidate in scores[:k]]\n",
    "\n",
    "    def _compute_concept_score(self, candidate: Dict, task_direction: str) -> float:\n",
    "        \"\"\"Compute probability of predicting concept tokens\"\"\"\n",
    "        if task_direction == \"X->Y\":\n",
    "            input_text = candidate[\"input\"]\n",
    "            target_text = candidate[\"output\"]\n",
    "        else:  # Y->X\n",
    "            input_text = candidate[\"output\"]\n",
    "            target_text = candidate[\"input\"]\n",
    "            \n",
    "        inputs = self.concept_learner.tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.concept_learner.model(**inputs)\n",
    "            \n",
    "        # Compute probability of concept tokens\n",
    "        concept_token_ids = self._get_concept_token_ids(candidate[\"task\"])\n",
    "        probs = torch.softmax(outputs.logits[:, -1], dim=-1)\n",
    "        score = probs[:, concept_token_ids].mean().item()\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "class MetaICL:\n",
    "    \"\"\"\n",
    "    Main class combining core functionality and analysis capabilities\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        # Core components\n",
    "        self.concept_learner = ConceptLearner(config)\n",
    "        self.demonstration_selector = DemonstrationSelector(self.concept_learner)\n",
    "        \n",
    "        # Analysis components\n",
    "        self.concept_visualizer = ConceptTokenVisualizer(self.concept_learner)\n",
    "        self.demo_analyzer = DemonstrationAnalyzer(self.demonstration_selector)\n",
    "        self.performance_analyzer = PerformanceAnalyzer()\n",
    "\n",
    "    def train(self, train_data: List[Dict], task_direction: str = \"X->Y\") -> None:\n",
    "        \"\"\"Train concept tokens\"\"\"\n",
    "        tasks = list(set(x[\"task\"] for x in train_data))\n",
    "        self.concept_learner.add_concept_tokens(tasks)\n",
    "        self.concept_learner.train(train_data, task_direction)\n",
    "        \n",
    "    def select_demonstrations(\n",
    "        self,\n",
    "        candidates: List[Dict],\n",
    "        k: int = 4,\n",
    "        task_direction: str = \"X->Y\"\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Select demonstrations\"\"\"\n",
    "        return self.demonstration_selector.select_demonstrations(\n",
    "            candidates,\n",
    "            k,\n",
    "            task_direction\n",
    "        )\n",
    "        \n",
    "    def do_inference(\n",
    "        self,\n",
    "        test_input: str,\n",
    "        demonstrations: List[Dict],\n",
    "        target_model: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Perform in-context learning inference\"\"\"\n",
    "        if target_model:\n",
    "            model = AutoModelForCausalLM.from_pretrained(target_model)\n",
    "            tokenizer = AutoTokenizer.from_pretrained(target_model)\n",
    "        else:\n",
    "            model = self.concept_learner.model\n",
    "            tokenizer = self.concept_learner.tokenizer\n",
    "            \n",
    "        prompt = self._format_prompt(test_input, demonstrations)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs)\n",
    "        \n",
    "        return tokenizer.decode(outputs[0])\n",
    "\n",
    "    # Analysis methods\n",
    "    def analyze_concept_tokens(self, tasks: List[str], save_path: Optional[str] = None):\n",
    "        \"\"\"Analyze learned concept tokens\"\"\"\n",
    "        self.concept_visualizer.plot_concept_embeddings(tasks, save_path)\n",
    "        return self.concept_visualizer.find_similar_tokens(tasks)\n",
    "                \n",
    "    def analyze_demonstrations(self, candidates: List[Dict], task: str):\n",
    "        \"\"\"Analyze demonstration selection\"\"\"\n",
    "        scores = self.demo_analyzer.plot_score_distribution(candidates, task)\n",
    "        demonstrations = self.select_demonstrations(candidates)\n",
    "        diversity = self.demo_analyzer.analyze_demonstration_diversity(demonstrations)\n",
    "        \n",
    "        return {\n",
    "            'scores': scores,\n",
    "            'diversity_metrics': diversity,\n",
    "            'selected_demonstrations': demonstrations\n",
    "        }\n",
    "\n",
    "    def log_experiment(self, name: str, accuracy: float, params: Dict):\n",
    "        \"\"\"Log experimental results\"\"\"\n",
    "        self.performance_analyzer.log_experiment(name, accuracy, params)\n",
    "\n",
    "    def plot_ablation_study(self, parameter: str, experiments: List[str]):\n",
    "        \"\"\"Generate ablation study visualization\"\"\"\n",
    "        return self.performance_analyzer.plot_ablation_study(parameter, experiments)\n",
    "\n",
    "    def _format_prompt(self, input_text: str, demonstrations: List[Dict]) -> str:\n",
    "        \"\"\"Helper method to format prompt with demonstrations\"\"\"\n",
    "        prompt = \"\"\n",
    "        for demo in demonstrations:\n",
    "            prompt += f\"{demo['input']} {demo['output']}\\n\\n\"\n",
    "        prompt += input_text\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/marketpulse/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class ConceptTokenVisualizer:\n",
    "    \"\"\"\n",
    "    Visualizes learned concept tokens and their relationships\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_learner):\n",
    "        self.concept_learner = concept_learner\n",
    "        self.tsne = TSNE(n_components=2, random_state=42)\n",
    "class ConceptTokenVisualizer:\n",
    "    def __init__(self, concept_learner):\n",
    "        self.concept_learner = concept_learner\n",
    "\n",
    "    def plot_concept_embeddings(self, tasks: List[str]):\n",
    "        \"\"\"\n",
    "        Visualize concept token embeddings with t-SNE\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "\n",
    "        embedding_matrix = self.concept_learner.model.get_input_embeddings().weight\n",
    "        for task in tasks:\n",
    "            token_ids = self._get_concept_token_ids(task)\n",
    "            task_embeddings = embedding_matrix[token_ids].detach().cpu().numpy()\n",
    "            embeddings.append(task_embeddings)\n",
    "            labels.extend([task] * len(token_ids))\n",
    "\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        n_samples = embeddings.shape[0]\n",
    "        perplexity = min(30, n_samples - 1)\n",
    "\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "        tsne_result = tsne.fit_transform(embeddings)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(\n",
    "            x=tsne_result[:, 0],\n",
    "            y=tsne_result[:, 1],\n",
    "            hue=labels,\n",
    "            style=labels,\n",
    "            s=100\n",
    "        )\n",
    "        plt.title(\"t-SNE Visualization of Concept Token Embeddings (Tasks)\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        def _get_concept_token_ids(self, task: str):\n",
    "            \"\"\"\n",
    "            Helper to get concept token IDs for a task\n",
    "            \"\"\"\n",
    "            token_ids = [\n",
    "                self.concept_learner.tokenizer.convert_tokens_to_ids(f\"<{task}_token_{i}>\")\n",
    "                for i in range(self.concept_learner.config.n_prefix_tokens)\n",
    "            ]\n",
    "            return token_ids\n",
    "\n",
    "        def plot_token_contributions(self, input_text: str, task: str):\n",
    "            \"\"\"\n",
    "            Visualize token contributions using attention weights\n",
    "            \"\"\"\n",
    "            inputs = self.concept_learner.tokenizer(input_text, return_tensors=\"pt\")\n",
    "            outputs = self.concept_learner.model(**inputs, output_attentions=True)\n",
    "            \n",
    "            # Average over heads and remove batch dimension\n",
    "            attention_scores = outputs.attentions[-1].mean(dim=1).squeeze(0).detach().cpu().numpy()\n",
    "            \n",
    "            # Use the last layer and take mean attention scores for tokens\n",
    "            token_attention_scores = attention_scores.mean(axis=0)\n",
    "            \n",
    "            # Tokens must be aligned with attention scores\n",
    "            tokens = self.concept_learner.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "            \n",
    "            plt.figure(figsize=(15, 5))\n",
    "            sns.barplot(x=tokens, y=token_attention_scores)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.title(f\"Token Contributions for Task: {task}\")\n",
    "            plt.xlabel(\"Tokens\")\n",
    "            plt.ylabel(\"Attention Score\")\n",
    "            plt.show()\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "\n",
    "class ConceptLearner:\n",
    "    \"\"\"\n",
    "    Handles latent concept learning\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(config.model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]):\n",
    "        \"\"\"\n",
    "        Add new concept tokens for each task\n",
    "        \"\"\"\n",
    "        new_tokens = [f\"<{task}_token_{i}>\" for task in tasks for i in range(self.config.n_prefix_tokens)]\n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def train(self, train_data: List[Dict]):\n",
    "        \"\"\"\n",
    "        Train concept tokens\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [self.model.get_input_embeddings().weight],\n",
    "            lr=self.config.learning_rate\n",
    "        )\n",
    "        for step, batch in enumerate(train_data):\n",
    "            inputs = self.tokenizer(batch[\"input\"], return_tensors=\"pt\")\n",
    "            outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "class DemonstrationSelector:\n",
    "    \"\"\"\n",
    "    Handles demonstration selection phase\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_learner: ConceptLearner):\n",
    "        self.concept_learner = concept_learner\n",
    "\n",
    "    def select_demonstrations(self, candidates: List[Dict], k: int):\n",
    "        \"\"\"\n",
    "        Select top-k demonstrations\n",
    "        \"\"\"\n",
    "        scores = [(self._compute_concept_score(c), c) for c in candidates]\n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [c for _, c in scores[:k]]\n",
    "\n",
    "    def _compute_concept_score(self, candidate: Dict):\n",
    "        \"\"\"\n",
    "        Compute demonstration relevance score\n",
    "        \"\"\"\n",
    "        inputs = self.concept_learner.tokenizer(candidate[\"input\"], return_tensors=\"pt\")\n",
    "        outputs = self.concept_learner.model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits[:, -1], dim=-1)\n",
    "        concept_token_ids = self.concept_learner.tokenizer.convert_tokens_to_ids(candidate[\"task\"])\n",
    "        return probs[:, concept_token_ids].mean().item()\n",
    "\n",
    "class MetaICL:\n",
    "    \"\"\"\n",
    "    Main class combining core functionality and explanations\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.concept_learner = ConceptLearner(config)\n",
    "        self.visualizer = ConceptTokenVisualizer(self.concept_learner)\n",
    "        self.selector = DemonstrationSelector(self.concept_learner)\n",
    "\n",
    "    def train(self, train_data: List[Dict], tasks: List[str]):\n",
    "        \"\"\"\n",
    "        Train the model and add concept tokens\n",
    "        \"\"\"\n",
    "        self.concept_learner.add_concept_tokens(tasks)\n",
    "        self.concept_learner.train(train_data)\n",
    "\n",
    "    def explain(self, input_text: str, candidates: List[Dict], task: str, k: int):\n",
    "        \"\"\"\n",
    "        Provide explanations for a task\n",
    "        \"\"\"\n",
    "        print(\"Visualizing concept embeddings...\")\n",
    "        self.visualizer.plot_concept_embeddings([task])\n",
    "\n",
    "        print(\"Visualizing token contributions...\")\n",
    "        self.visualizer.plot_token_contributions(input_text, task)\n",
    "\n",
    "        print(\"Analyzing demonstration relevance...\")\n",
    "        selected_demos = self.selector.select_demonstrations(candidates, k)\n",
    "        print(\"Selected Demonstrations:\", selected_demos)\n",
    "        return selected_demos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Configuration\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=5, learning_rate=1e-4)\n",
    "meta_icl = MetaICL(config)\n",
    "\n",
    "# Train the Model\n",
    "tasks = [\"arithmetic\", \"text_classification\"]\n",
    "train_data = [\n",
    "    {\"input\": \"2 + 2 =\", \"output\": \"4\", \"task\": \"arithmetic\"},\n",
    "    {\"input\": \"The cat sat on the mat.\", \"output\": \"Positive\", \"task\": \"text_classification\"}\n",
    "]\n",
    "meta_icl.train(train_data, tasks)\n",
    "\n",
    "# Explain a Task\n",
    "input_text = \"What is 7 + 3?\"\n",
    "candidates = [\n",
    "    {\"input\": \"5 + 2 =\", \"output\": \"7\", \"task\": \"arithmetic\"},\n",
    "    {\"input\": \"The dog is barking.\", \"output\": \"Negative\", \"task\": \"text_classification\"}\n",
    "]\n",
    "meta_icl.explain(input_text, candidates, task=\"arithmetic\", k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/marketpulse/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/marketpulse/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketpulse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
