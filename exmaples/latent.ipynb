{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
       "            <style>\n",
       "                .section-title {\n",
       "                    font-weight: bold;\n",
       "                    margin: 10px 0;\n",
       "                    color: #2c5282;\n",
       "                    font-size: 20px;\n",
       "                }\n",
       "                .demonstration-card {\n",
       "                    margin: 10px 0;\n",
       "                    padding: 15px;\n",
       "                    border-radius: 8px;\n",
       "                    background-color: #f8f9fa;\n",
       "                    border: 1px solid #ddd;\n",
       "                }\n",
       "                .demonstration-header {\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #2c5282;\n",
       "                    margin-bottom: 10px;\n",
       "                }\n",
       "                .token-container {\n",
       "                    margin-top: 10px;\n",
       "                    display: flex;\n",
       "                    flex-wrap: wrap;\n",
       "                }\n",
       "                .token {\n",
       "                    display: inline-block;\n",
       "                    margin: 5px;\n",
       "                    padding: 5px 8px;\n",
       "                    border-radius: 4px;\n",
       "                    font-size: 14px;\n",
       "                    position: relative;\n",
       "                    cursor: pointer;\n",
       "                    background-color: rgb(255, 255, 255);\n",
       "                }\n",
       "                .token[data-score] {\n",
       "                    background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2));\n",
       "                    color: black;\n",
       "                }\n",
       "                .token:hover {\n",
       "                    background-color: rgba(255, 0, 0, 1);\n",
       "                }\n",
       "                .token:hover .tooltip {\n",
       "                    display: block;\n",
       "                }\n",
       "                .tooltip {\n",
       "                    display: none;\n",
       "                    position: absolute;\n",
       "                    top: -30px;\n",
       "                    left: 50%;\n",
       "                    transform: translateX(-50%);\n",
       "                    background-color: #333;\n",
       "                    color: white;\n",
       "                    padding: 5px 8px;\n",
       "                    border-radius: 4px;\n",
       "                    font-size: 12px;\n",
       "                    z-index: 10;\n",
       "                }\n",
       "            </style>\n",
       "            \n",
       "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
       "            <div id=\"demonstration-container\">\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.838</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.6394267984578837\" data-score=\"0.6394267984578837\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.64</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.025010755222666936\" data-score=\"0.025010755222666936\">\n",
       "                                article\n",
       "                                <span class=\"tooltip\">Score: 0.03</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.27502931836911926\" data-score=\"0.27502931836911926\">\n",
       "                                explained\n",
       "                                <span class=\"tooltip\">Score: 0.28</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.22321073814882275\" data-score=\"0.22321073814882275\">\n",
       "                                AI\n",
       "                                <span class=\"tooltip\">Score: 0.22</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.7364712141640124\" data-score=\"0.7364712141640124\">\n",
       "                                clearly.\n",
       "                                <span class=\"tooltip\">Score: 0.74</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"demonstration-card\">\n",
       "                    <div class=\"demonstration-header\">Demonstration Score: 0.609</div>\n",
       "                    <div>\n",
       "                        <b>Token Contributions:</b>\n",
       "                        <div class=\"token-container\">\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.8921795677048454\" data-score=\"0.8921795677048454\">\n",
       "                                The\n",
       "                                <span class=\"tooltip\">Score: 0.89</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.08693883262941615\" data-score=\"0.08693883262941615\">\n",
       "                                novel\n",
       "                                <span class=\"tooltip\">Score: 0.09</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.4219218196852704\" data-score=\"0.4219218196852704\">\n",
       "                                was\n",
       "                                <span class=\"tooltip\">Score: 0.42</span>\n",
       "                            </div>\n",
       "                            \n",
       "                            <div class=\"token\" style=\"--score: 0.029797219438070344\" data-score=\"0.029797219438070344\">\n",
       "                                thrilling.\n",
       "                                <span class=\"tooltip\">Score: 0.03</span>\n",
       "                            </div>\n",
       "                            \n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Union, Literal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from IPython.display import HTML, display\n",
    "from jinja2 import Template\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    \"\"\"Represents the causal direction as described in the paper.\"\"\"\n",
    "    X_TO_Y = \"X->Y->theta\"  # X → Y ← θ\n",
    "    Y_TO_X = \"Y->X->theta\"  # Y → X ← θ\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the model and training process.\"\"\"\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 10000\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def compute_token_contributions(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Compute token contributions using task-specific latent variable alignment.\"\"\"\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.config.device)\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        # Extract hidden states and attentions\n",
    "        attentions = outputs.attentions\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "        # Compute attention contributions\n",
    "        layer_contributions = [\n",
    "            layer_att.mean(dim=1).sum(dim=2)\n",
    "            for layer_att in attentions\n",
    "        ]\n",
    "\n",
    "        # Aggregate across layers with task-specific weighting\n",
    "        num_layers = len(attentions)\n",
    "        layer_weights = torch.linspace(0.1, 1.0, steps=num_layers).to(self.config.device)\n",
    "        weighted_contributions = torch.stack(layer_contributions, dim=0) * layer_weights[:, None, None]\n",
    "        token_contributions = weighted_contributions.sum(dim=0)\n",
    "\n",
    "        # Normalize contributions\n",
    "        normalized_contributions = token_contributions / token_contributions.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # Map tokens to scores\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "        return [{\"token\": token, \"score\": float(score)} \n",
    "                for token, score in zip(tokens, normalized_contributions.squeeze().tolist())]\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        \"\"\"Add new concept tokens for each task.\"\"\"\n",
    "        new_tokens = []\n",
    "        for task in tasks:\n",
    "            task_tokens = [f\"<{task}_token_{i}>\" for i in range(self.config.n_prefix_tokens)]\n",
    "            new_tokens.extend(task_tokens)\n",
    "        \n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        \"\"\"Train concept tokens using Algorithm 1 from the paper.\"\"\"\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        optimizer = AdamW(\n",
    "            [p for n, p in self.model.named_parameters() if \"wte\" in n],\n",
    "            lr=self.config.learning_rate\n",
    "        )\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "\n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item, concept_tokens[tasks.index(item[\"task\"])], direction)\n",
    "                total_loss += loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def _compute_batch_loss(self, item: Dict, concept_token: str, direction: CausalDirection) -> torch.Tensor:\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            inputs = self._prepare_xy_input(item[\"text\"], concept_token)\n",
    "            labels = self.tokenizer(item[\"label\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "        else:\n",
    "            inputs = self._prepare_yx_input(item[\"label\"], concept_token)\n",
    "            labels = self.tokenizer(item[\"text\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "\n",
    "        outputs = self.model(**inputs, labels=labels)\n",
    "        return outputs.loss\n",
    "\n",
    "    def _prepare_xy_input(self, text: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {text}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "    def _prepare_yx_input(self, label: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {label}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "class DemonstrationSelector:\n",
    "    def __init__(self, concept_learner: ConceptLearner):\n",
    "        self.concept_learner = concept_learner\n",
    "\n",
    "    def select_demonstrations(self, candidates: List[Dict], k: int):\n",
    "        \"\"\"\n",
    "        Select top-k demonstrations based on model scores.\n",
    "        \"\"\"\n",
    "        scores = [(self._compute_concept_score(c), c) for c in candidates]\n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [c for _, c in scores[:k]]\n",
    "\n",
    "    def _compute_concept_score(self, candidate: Dict):\n",
    "        \"\"\"\n",
    "        Compute demonstration relevance score using log probabilities.\n",
    "        \"\"\"\n",
    "        inputs = self.concept_learner.tokenizer(candidate[\"input\"], return_tensors=\"pt\")\n",
    "        outputs = self.concept_learner.model(**inputs)\n",
    "        logits = outputs.logits[:, :-1, :]  # Skip the last token prediction\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Tokenize output and calculate score for output tokens\n",
    "        target_ids = self.concept_learner.tokenizer(candidate[\"output\"], return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "        scores = [probs[0, i, target_id].item() for i, target_id in enumerate(target_ids)]\n",
    "        return sum(scores) / len(scores)  # Average log probabilities\n",
    "\n",
    "    def evaluate_demonstrations(self, test_set: List[Dict], selected_demos: List[Dict]):\n",
    "        \"\"\"\n",
    "        Evaluate selected demonstrations on a test set.\n",
    "        \"\"\"\n",
    "        total_loss = 0\n",
    "        for example in test_set:\n",
    "            inputs = self.concept_learner.tokenizer(\n",
    "                selected_demos + [example[\"input\"]], return_tensors=\"pt\", truncation=True\n",
    "            )\n",
    "            outputs = self.concept_learner.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            total_loss += outputs.loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(test_set)\n",
    "        print(f\"Evaluation Loss: {avg_loss}\")\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "class DashboardVisualizer:\n",
    "    def __init__(self, demonstration_scores):\n",
    "        \"\"\"\n",
    "        Initialize DashboardVisualizer with data for visualization.\n",
    "        \"\"\"\n",
    "        self.demonstration_scores = demonstration_scores  # Scores for all demonstrations\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        \"\"\"\n",
    "        Create an interactive HTML dashboard.\n",
    "        \"\"\"\n",
    "        html_template = '''\n",
    "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
    "            <style>\n",
    "                .section-title {\n",
    "                    font-weight: bold;\n",
    "                    margin: 10px 0;\n",
    "                    color: #2c5282;\n",
    "                    font-size: 20px;\n",
    "                }\n",
    "                .demonstration-card {\n",
    "                    margin: 10px 0;\n",
    "                    padding: 15px;\n",
    "                    border-radius: 8px;\n",
    "                    background-color: #f8f9fa;\n",
    "                    border: 1px solid #ddd;\n",
    "                }\n",
    "                .demonstration-header {\n",
    "                    font-size: 16px;\n",
    "                    font-weight: bold;\n",
    "                    color: #2c5282;\n",
    "                    margin-bottom: 10px;\n",
    "                }\n",
    "                .token-container {\n",
    "                    margin-top: 10px;\n",
    "                    display: flex;\n",
    "                    flex-wrap: wrap;\n",
    "                }\n",
    "                .token {\n",
    "                    display: inline-block;\n",
    "                    margin: 5px;\n",
    "                    padding: 5px 8px;\n",
    "                    border-radius: 4px;\n",
    "                    font-size: 14px;\n",
    "                    position: relative;\n",
    "                    cursor: pointer;\n",
    "                    background-color: rgb(255, 255, 255);\n",
    "                }\n",
    "                .token[data-score] {\n",
    "                    background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2));\n",
    "                    color: black;\n",
    "                }\n",
    "                .token:hover {\n",
    "                    background-color: rgba(255, 0, 0, 1);\n",
    "                }\n",
    "                .token:hover .tooltip {\n",
    "                    display: block;\n",
    "                }\n",
    "                .tooltip {\n",
    "                    display: none;\n",
    "                    position: absolute;\n",
    "                    top: -30px;\n",
    "                    left: 50%;\n",
    "                    transform: translateX(-50%);\n",
    "                    background-color: #333;\n",
    "                    color: white;\n",
    "                    padding: 5px 8px;\n",
    "                    border-radius: 4px;\n",
    "                    font-size: 12px;\n",
    "                    z-index: 10;\n",
    "                }\n",
    "            </style>\n",
    "            \n",
    "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
    "            <div id=\"demonstration-container\">\n",
    "                {% for demo in demonstration_scores %}\n",
    "                <div class=\"demonstration-card\">\n",
    "                    <div class=\"demonstration-header\">Demonstration Score: {{ \"%.3f\"|format(demo.score) }}</div>\n",
    "                    <div>\n",
    "                        <b>Token Contributions:</b>\n",
    "                        <div class=\"token-container\">\n",
    "                            {% for token in demo.token_contributions %}\n",
    "                            <div class=\"token\" style=\"--score: {{ token.score }}\" data-score=\"{{ token.score }}\">\n",
    "                                {{ token.token }}\n",
    "                                <span class=\"tooltip\">Score: {{ \"%.2f\"|format(token.score) }}</span>\n",
    "                            </div>\n",
    "                            {% endfor %}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        template = Template(html_template)\n",
    "        rendered_html = template.render(\n",
    "            demonstration_scores=self.demonstration_scores,\n",
    "        )\n",
    "        display(HTML(rendered_html))\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "\n",
    "    # Configuration\n",
    "    config = ModelConfig(model_name=\"gpt2-xl\", n_prefix_tokens=5, learning_rate=1e-4)\n",
    "    concept_learner = ConceptLearner(config)\n",
    "    demonstration_selector = DemonstrationSelector(concept_learner)\n",
    "\n",
    "    # Example Demonstrations\n",
    "    candidates = [\n",
    "        {\"input\": \"The movie was great.\", \"output\": \"positive\"},\n",
    "        {\"input\": \"The book was boring.\", \"output\": \"negative\"},\n",
    "        {\"input\": \"The article explained AI clearly.\", \"output\": \"informative\"},\n",
    "        {\"input\": \"The novel was thrilling.\", \"output\": \"exciting\"},\n",
    "    ]\n",
    "\n",
    "    # Select Demonstrations\n",
    "    selected_demos = demonstration_selector.select_demonstrations(candidates, k=2)\n",
    "\n",
    "    # Mock Token Contributions for each Demonstration\n",
    "    demonstration_scores = []\n",
    "    for demo in selected_demos:\n",
    "        tokens = demo[\"input\"].split()\n",
    "        token_contributions = [{\"token\": token, \"score\": random.uniform(0, 1)} for token in tokens]\n",
    "        demonstration_scores.append({\"score\": random.uniform(0.5, 1), \"token_contributions\": token_contributions})\n",
    "\n",
    "    # Create and Display Dashboard\n",
    "    dashboard = DashboardVisualizer(demonstration_scores=demonstration_scores)\n",
    "    dashboard.create_dashboard()\n",
    "\n",
    "\n",
    "# Run the main example\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Preferred split 'train' not found. Using 'validation' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HFConceptLearner' object has no attribute 'model_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 241\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 228\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m learner \u001b[38;5;241m=\u001b[39m HFConceptLearner(model_config, data_config)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Train concepts\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_concepts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment_analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Select demonstrations\u001b[39;00m\n\u001b[1;32m    231\u001b[0m demos \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mselect_demonstrations(\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 139\u001b[0m, in \u001b[0;36mHFConceptLearner.train_concepts\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train concept tokens using Hugging Face dataset\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m concept_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept_learner\u001b[38;5;241m.\u001b[39madd_concept_tokens(tasks)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241m.\u001b[39mnum_train_steps):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader:\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[1;32m    142\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[1;32m    143\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor)}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HFConceptLearner' object has no attribute 'model_config'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_split_names\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from typing import Optional, Dict, List, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass \n",
    "class DataConfig:\n",
    "    \"\"\"Configuration for dataset loading and processing\"\"\"\n",
    "    dataset_name: str\n",
    "    text_column: str = \"text\"\n",
    "    label_column: str = \"label\"\n",
    "    preferred_train_split: str = \"train\"  # Preferred but not required\n",
    "    preferred_test_split: str = \"test\"    # Preferred but not required\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "\n",
    "class HFConceptDataset(Dataset):\n",
    "    \"\"\"Wrapper for Hugging Face datasets to work with concept learning\"\"\"\n",
    "    def __init__(self, \n",
    "                 dataset_name: str,\n",
    "                 tokenizer,\n",
    "                 config: DataConfig,\n",
    "                 split: Optional[str] = None):\n",
    "        # Get available splits for the dataset\n",
    "        available_splits = get_dataset_split_names(dataset_name)\n",
    "        \n",
    "        if not available_splits:\n",
    "            raise ValueError(f\"No splits found for dataset {dataset_name}\")\n",
    "            \n",
    "        # If no split specified, try to find an appropriate one\n",
    "        if split is None:\n",
    "            if config.preferred_train_split in available_splits:\n",
    "                split = config.preferred_train_split\n",
    "            else:\n",
    "                # Use the first available split as fallback\n",
    "                split = available_splits[0]\n",
    "                print(f\"Warning: Preferred split '{config.preferred_train_split}' not found. Using '{split}' instead.\")\n",
    "        \n",
    "        self.dataset = load_dataset(dataset_name, split=split)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        # Handle cases where column names might be different\n",
    "        text_field = self.config.text_column\n",
    "        if text_field not in item:\n",
    "            # Try to find an appropriate text field\n",
    "            text_candidates = [\"text\", \"sentence\", \"content\"]\n",
    "            for candidate in text_candidates:\n",
    "                if candidate in item:\n",
    "                    text_field = candidate\n",
    "                    break\n",
    "            else:\n",
    "                raise KeyError(f\"Could not find text field in dataset. Available fields: {list(item.keys())}\")\n",
    "        \n",
    "        label_field = self.config.label_column\n",
    "        if label_field not in item:\n",
    "            # Try to find an appropriate label field\n",
    "            label_candidates = [\"label\", \"labels\", \"class\", \"target\"]\n",
    "            for candidate in label_candidates:\n",
    "                if candidate in item:\n",
    "                    label_field = candidate\n",
    "                    break\n",
    "            else:\n",
    "                raise KeyError(f\"Could not find label field in dataset. Available fields: {list(item.keys())}\")\n",
    "        \n",
    "        text = item[text_field]\n",
    "        label = item[label_field]\n",
    "        \n",
    "        # Handle tokenization\n",
    "        try:\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.config.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error tokenizing text: {text}\")\n",
    "            raise e\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "class HFConceptLearner:\n",
    "    \"\"\"Adapter class to use ConceptLearner with Hugging Face datasets\"\"\"\n",
    "    def __init__(self, \n",
    "                 model_config: ModelConfig,\n",
    "                 data_config: DataConfig):\n",
    "        self.concept_learner = ConceptLearner(model_config)\n",
    "        self.data_config = data_config\n",
    "        \n",
    "        try:\n",
    "            # Initialize dataset\n",
    "            self.dataset = HFConceptDataset(\n",
    "                data_config.dataset_name,\n",
    "                self.concept_learner.tokenizer,\n",
    "                data_config\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing dataset: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        self.dataloader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=data_config.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def _get_appropriate_split(self, split_type: str = \"train\") -> str:\n",
    "        \"\"\"Helper method to find an appropriate dataset split\"\"\"\n",
    "        available_splits = get_dataset_split_names(self.data_config.dataset_name)\n",
    "        preferred_splits = {\n",
    "            \"train\": [self.data_config.preferred_train_split, \"train\", \"validation\"],\n",
    "            \"test\": [self.data_config.preferred_test_split, \"test\", \"validation\"]\n",
    "        }\n",
    "        \n",
    "        for split in preferred_splits[split_type]:\n",
    "            if split in available_splits:\n",
    "                return split\n",
    "                \n",
    "        return available_splits[0]  # Fallback to first available split\n",
    "\n",
    "    def train_concepts(self, tasks: List[str]):\n",
    "        \"\"\"Train concept tokens using Hugging Face dataset\"\"\"\n",
    "        concept_tokens = self.concept_learner.add_concept_tokens(tasks)\n",
    "        \n",
    "        for epoch in range(self.model_config.num_train_steps):\n",
    "            for batch in self.dataloader:\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(self.model_config.device) \n",
    "                        for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "                \n",
    "                total_loss = self.concept_learner.compute_batch_loss(\n",
    "                    batch, concept_tokens[tasks.index(batch[\"task\"])],\n",
    "                    self.direction\n",
    "                )\n",
    "                \n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "    def select_demonstrations(self, \n",
    "                            num_demos: int,\n",
    "                            test_dataset: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Select demonstrations from Hugging Face dataset\"\"\"\n",
    "        if test_dataset is None:\n",
    "            test_split = self._get_appropriate_split(\"test\")\n",
    "            test_dataset = self.data_config.dataset_name\n",
    "        else:\n",
    "            test_split = self._get_appropriate_split(\"test\")\n",
    "            \n",
    "        test_data = load_dataset(test_dataset, split=test_split)\n",
    "        \n",
    "        selector = DemonstrationSelector(self.concept_learner)\n",
    "        \n",
    "        # Convert dataset to list of dicts for selector\n",
    "        candidates = [{\n",
    "            'input': item[self.data_config.text_column],\n",
    "            'output': str(item[self.data_config.label_column])\n",
    "        } for item in self.dataset]\n",
    "        \n",
    "        return selector.select_demonstrations(candidates, num_demos)\n",
    "\n",
    "    def evaluate(self, \n",
    "                test_dataset: Optional[str] = None,\n",
    "                demos: Optional[List[Dict]] = None):\n",
    "        \"\"\"Evaluate using selected demonstrations on test set\"\"\"\n",
    "        if test_dataset is None:\n",
    "            test_split = self._get_appropriate_split(\"test\")\n",
    "            test_dataset = self.data_config.dataset_name\n",
    "        else:\n",
    "            test_split = self._get_appropriate_split(\"test\")\n",
    "            \n",
    "        test_data = load_dataset(test_dataset, split=test_split)\n",
    "        \n",
    "        if demos is None:\n",
    "            demos = self.select_demonstrations(4)\n",
    "            \n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            inputs = self.concept_learner.tokenizer(\n",
    "                demos + [item[self.data_config.text_column]],\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True\n",
    "            ).to(self.model_config.device)\n",
    "            \n",
    "            outputs = self.concept_learner.model(**inputs)\n",
    "            pred = torch.argmax(outputs.logits[:, -1, :]).item()\n",
    "            \n",
    "            results.append({\n",
    "                'text': item[self.data_config.text_column],\n",
    "                'true': item[self.data_config.label_column],\n",
    "                'pred': pred\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    model_config = ModelConfig(\n",
    "        model_name=\"gpt2\",\n",
    "        n_prefix_tokens=10,\n",
    "        learning_rate=1e-4\n",
    "    )\n",
    "    \n",
    "    data_config = DataConfig(\n",
    "        dataset_name=\"gimmaru/glue-sst2\",\n",
    "        text_column=\"sentence\",\n",
    "        label_column=\"label\"\n",
    "    )\n",
    "    \n",
    "    learner = HFConceptLearner(model_config, data_config)\n",
    "    \n",
    "    # Train concepts\n",
    "    learner.train_concepts([\"sentiment_analysis\"])\n",
    "    \n",
    "    # Select demonstrations\n",
    "    demos = learner.select_demonstrations(4)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = learner.evaluate(demos=demos)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = sum(r['true'] == r['pred'] for r in results) / len(results)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihongxuan/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n",
      "/Users/lihongxuan/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DemonstrationSelector' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 290\u001b[0m\n\u001b[1;32m    282\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    283\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe movie was great.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    284\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe book was boring.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    285\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe article explained AI clearly.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformative\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    286\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe novel was thrilling.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexciting\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    287\u001b[0m ]\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Select demonstrations\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m selected_demos \u001b[38;5;241m=\u001b[39m \u001b[43mdemonstration_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_demonstrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Create and display dashboard\u001b[39;00m\n\u001b[1;32m    293\u001b[0m dashboard \u001b[38;5;241m=\u001b[39m DashboardVisualizer(demonstration_scores\u001b[38;5;241m=\u001b[39mselected_demos)\n",
      "Cell \u001b[0;32mIn[10], line 141\u001b[0m, in \u001b[0;36mDemonstrationSelector.select_demonstrations\u001b[0;34m(self, candidates, k)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m demo \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[1;32m    140\u001b[0m     token_contributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept_learner\u001b[38;5;241m.\u001b[39mcompute_token_contributions(demo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_demo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     demonstration_scores\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    143\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: score, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_contributions\u001b[39m\u001b[38;5;124m\"\u001b[39m: token_contributions}\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    146\u001b[0m demonstration_scores\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 151\u001b[0m, in \u001b[0;36mDemonstrationSelector._compute_demo_score\u001b[0;34m(self, demo)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_demo_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, demo: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute demonstration score using latent variable alignment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m(\n\u001b[1;32m    152\u001b[0m         demo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    153\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept_learner\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept_learner\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    157\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DemonstrationSelector' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Union, Literal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from IPython.display import HTML, display\n",
    "from jinja2 import Template\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "class CausalDirection(Enum):\n",
    "    \"\"\"Represents the causal direction as described in the paper.\"\"\"\n",
    "    X_TO_Y = \"X->Y->theta\"  # X → Y ← θ\n",
    "    Y_TO_X = \"Y->X->theta\"  # Y → X ← θ\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the model and training process.\"\"\"\n",
    "    model_name: str\n",
    "    n_prefix_tokens: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    max_length: int = 1024\n",
    "    batch_size: int = 16\n",
    "    num_train_steps: int = 10000\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class ConceptLearner:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_name,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        ).to(config.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def compute_token_contributions(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Compute token contributions using task-specific latent variable alignment.\"\"\"\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.config.device)\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        # Extract hidden states and attentions\n",
    "        attentions = outputs.attentions\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "        # Compute attention contributions\n",
    "        layer_contributions = [\n",
    "            layer_att.mean(dim=1).sum(dim=2)\n",
    "            for layer_att in attentions\n",
    "        ]\n",
    "\n",
    "        # Aggregate across layers with task-specific weighting\n",
    "        num_layers = len(attentions)\n",
    "        layer_weights = torch.linspace(0.1, 1.0, steps=num_layers).to(self.config.device)\n",
    "        weighted_contributions = torch.stack(layer_contributions, dim=0) * layer_weights[:, None, None]\n",
    "        token_contributions = weighted_contributions.sum(dim=0)\n",
    "\n",
    "        # Normalize contributions\n",
    "        normalized_contributions = token_contributions / token_contributions.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # Map tokens to scores\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze(0))\n",
    "        return [{\"token\": token, \"score\": float(score)} \n",
    "                for token, score in zip(tokens, normalized_contributions.squeeze().tolist())]\n",
    "\n",
    "    def add_concept_tokens(self, tasks: List[str]) -> List[str]:\n",
    "        \"\"\"Add new concept tokens for each task.\"\"\"\n",
    "        new_tokens = []\n",
    "        for task in tasks:\n",
    "            task_tokens = [f\"<{task}_token_{i}>\" for i in range(self.config.n_prefix_tokens)]\n",
    "            new_tokens.extend(task_tokens)\n",
    "        \n",
    "        self.tokenizer.add_tokens(new_tokens)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        return new_tokens\n",
    "\n",
    "    def train_concept_tokens(self, train_data: List[Dict], tasks: List[str], direction: CausalDirection):\n",
    "        \"\"\"Train concept tokens using Algorithm 1 from the paper.\"\"\"\n",
    "        concept_tokens = self.add_concept_tokens(tasks)\n",
    "        optimizer = AdamW(\n",
    "            [p for n, p in self.model.named_parameters() if \"wte\" in n],\n",
    "            lr=self.config.learning_rate\n",
    "        )\n",
    "\n",
    "        for step in range(self.config.num_train_steps):\n",
    "            batch = random.sample(train_data, min(self.config.batch_size, len(train_data)))\n",
    "            total_loss = torch.tensor(0.0, device=self.config.device)\n",
    "\n",
    "            for item in batch:\n",
    "                loss = self._compute_batch_loss(item, concept_tokens[tasks.index(item[\"task\"])], direction)\n",
    "                total_loss += loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def _compute_batch_loss(self, item: Dict, concept_token: str, direction: CausalDirection) -> torch.Tensor:\n",
    "        if direction == CausalDirection.X_TO_Y:\n",
    "            inputs = self._prepare_xy_input(item[\"text\"], concept_token)\n",
    "            labels = self.tokenizer(item[\"label\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "        else:\n",
    "            inputs = self._prepare_yx_input(item[\"label\"], concept_token)\n",
    "            labels = self.tokenizer(item[\"text\"], return_tensors=\"pt\")[\"input_ids\"].to(self.config.device)\n",
    "\n",
    "        outputs = self.model(**inputs, labels=labels)\n",
    "        return outputs.loss\n",
    "\n",
    "    def _prepare_xy_input(self, text: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {text}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "    def _prepare_yx_input(self, label: str, concept_token: str) -> Dict[str, torch.Tensor]:\n",
    "        inputs = self.tokenizer(f\"{concept_token} {label}\", return_tensors=\"pt\")\n",
    "        return {k: v.to(self.config.device) for k, v in inputs.items()}\n",
    "\n",
    "class DemonstrationSelector:\n",
    "    def __init__(self, concept_learner: ConceptLearner):\n",
    "        self.concept_learner = concept_learner\n",
    "\n",
    "    def select_demonstrations(self, candidates: List[Dict], k: int) -> List[Dict]:\n",
    "        \"\"\"Select top-k demonstrations based on concept token probabilities.\"\"\"\n",
    "        demonstration_scores = []\n",
    "\n",
    "        for demo in candidates:\n",
    "            token_contributions = self.concept_learner.compute_token_contributions(demo[\"input\"])\n",
    "            score = self._compute_demo_score(demo)\n",
    "            demonstration_scores.append(\n",
    "                {\"score\": score, \"token_contributions\": token_contributions}\n",
    "            )\n",
    "\n",
    "        demonstration_scores.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        return demonstration_scores[:k]\n",
    "\n",
    "    def _compute_demo_score(self, demo: Dict) -> float:\n",
    "        \"\"\"Compute demonstration score using latent variable alignment.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            demo[\"input\"],\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.concept_learner.config.device)\n",
    "        \n",
    "        outputs = self.concept_learner.model(**inputs)\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "        task_embedding = self._get_task_embedding(demo[\"output\"])\n",
    "        \n",
    "        alignment_score = torch.cosine_similarity(\n",
    "            hidden_states.mean(dim=1),\n",
    "            task_embedding,\n",
    "            dim=-1\n",
    "        ).item()\n",
    "        \n",
    "        return alignment_score\n",
    "\n",
    "    def _get_task_embedding(self, task_label: str) -> torch.Tensor:\n",
    "        \"\"\"Generate task-specific embedding using the output label.\"\"\"\n",
    "        task_inputs = self.concept_learner.tokenizer(\n",
    "            task_label,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.concept_learner.config.device)\n",
    "        task_hidden = self.concept_learner.model(**task_inputs).hidden_states[-1]\n",
    "        return task_hidden.mean(dim=1)\n",
    "\n",
    "class DashboardVisualizer:\n",
    "    \"\"\"Creates an interactive HTML dashboard for visualizing demonstrations.\"\"\"\n",
    "    def __init__(self, demonstration_scores):\n",
    "        self.demonstration_scores = demonstration_scores\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        \"\"\"Create an interactive HTML dashboard.\"\"\"\n",
    "        html_template = '''\n",
    "        <div style=\"font-family: Arial, sans-serif; max-width: 900px; margin: 20px auto;\">\n",
    "            <style>\n",
    "                .section-title {\n",
    "                    font-weight: bold;\n",
    "                    margin: 10px 0;\n",
    "                    color: #2c5282;\n",
    "                    font-size: 20px;\n",
    "                }\n",
    "                .demonstration-card {\n",
    "                    margin: 10px 0;\n",
    "                    padding: 15px;\n",
    "                    border-radius: 8px;\n",
    "                    background-color: #f8f9fa;\n",
    "                    border: 1px solid #ddd;\n",
    "                }\n",
    "                .demonstration-header {\n",
    "                    font-size: 16px;\n",
    "                    font-weight: bold;\n",
    "                    color: #2c5282;\n",
    "                    margin-bottom: 10px;\n",
    "                }\n",
    "                .token-container {\n",
    "                    margin-top: 10px;\n",
    "                    display: flex;\n",
    "                    flex-wrap: wrap;\n",
    "                }\n",
    "                .token {\n",
    "                    display: inline-block;\n",
    "                    margin: 5px;\n",
    "                    padding: 5px 8px;\n",
    "                    border-radius: 4px;\n",
    "                    font-size: 14px;\n",
    "                    position: relative;\n",
    "                    cursor: pointer;\n",
    "                    background-color: rgb(255, 255, 255);\n",
    "                }\n",
    "                .token[data-score] {\n",
    "                    background-color: rgba(255, 69, 0, calc(var(--score) * 0.8 + 0.2));\n",
    "                    color: black;\n",
    "                }\n",
    "                .token:hover {\n",
    "                    background-color: rgba(255, 0, 0, 1);\n",
    "                }\n",
    "                .token:hover .tooltip {\n",
    "                    display: block;\n",
    "                }\n",
    "                .tooltip {\n",
    "                    display: none;\n",
    "                    position: absolute;\n",
    "                    top: -30px;\n",
    "                    left: 50%;\n",
    "                    transform: translateX(-50%);\n",
    "                    background-color: #333;\n",
    "                    color: white;\n",
    "                    padding: 5px 8px;\n",
    "                    border-radius: 4px;\n",
    "                    font-size: 12px;\n",
    "                    z-index: 10;\n",
    "                }\n",
    "            </style>\n",
    "            \n",
    "            <div class=\"section-title\">Selected Demonstrations and Token Contributions</div>\n",
    "            <div id=\"demonstration-container\">\n",
    "                {% for demo in demonstration_scores %}\n",
    "                <div class=\"demonstration-card\">\n",
    "                    <div class=\"demonstration-header\">Demonstration Score: {{ \"%.3f\"|format(demo['score']) }}</div>\n",
    "                    <div>\n",
    "                        <b>Token Contributions:</b>\n",
    "                        <div class=\"token-container\">\n",
    "                            {% for token in demo['token_contributions'] %}\n",
    "                            <div class=\"token\" style=\"--score: {{ token['score'] }}\" data-score=\"{{ token['score'] }}\">\n",
    "                                {{ token['token'] }}\n",
    "                                <span class=\"tooltip\">Score: {{ \"%.2f\"|format(token['score']) }}</span>\n",
    "                            </div>\n",
    "                            {% endfor %}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        template = Template(html_template)\n",
    "        rendered_html = template.render(demonstration_scores=self.demonstration_scores)\n",
    "        display(HTML(rendered_html))\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "set_global_seed(42)\n",
    "\n",
    "# Initialize model and components\n",
    "config = ModelConfig(model_name=\"gpt2\", n_prefix_tokens=5, learning_rate=1e-3)\n",
    "concept_learner = ConceptLearner(config)\n",
    "demonstration_selector = DemonstrationSelector(concept_learner)\n",
    "\n",
    "# Example demonstrations\n",
    "candidates = [\n",
    "    {\"input\": \"The movie was great.\", \"output\": \"positive\"},\n",
    "    {\"input\": \"The book was boring.\", \"output\": \"negative\"},\n",
    "    {\"input\": \"The article explained AI clearly.\", \"output\": \"informative\"},\n",
    "    {\"input\": \"The novel was thrilling.\", \"output\": \"exciting\"},\n",
    "]\n",
    "\n",
    "# Select demonstrations\n",
    "selected_demos = demonstration_selector.select_demonstrations(candidates, k=2)\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard = DashboardVisualizer(demonstration_scores=selected_demos)\n",
    "dashboard.create_dashboard()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAIjCAYAAABh3KjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT3klEQVR4nO3deVgV5f//8ddhR1ZRFFHcN1xyIxVLMaWwLDU100zFJSsrza20T7lU5r63aPlJzSVN82NlZpdiuOeCabm2mZqGuAHiBnLm94c/z7eTiBzlDAHPx3XNleeee2bec5jIV/fMPRbDMAwBAAAAAEzjktcFAAAAAEBhQxADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAOAQiAtLU19+vRRSEiILBaLXn755bwuKdeMGjVKFoslr8u4pX97fWYpX768YmNjnbLv2NhYlS9f3in7BgBnIYgBQD4wb948WSwW7dq16462f+eddzRv3jw9//zzWrBggbp165bLFTrXpUuXNGrUKMXHx+d1KXYsFkuWS0hISF6XdkuZmZkKDQ2VxWLRN998k9flAECh5ZbXBQAAnG/9+vVq3LixRo4cmdel3JFLly5p9OjRkqTmzZvbrXv99dc1bNiwPKjqugcffFDdu3e3a/P29s6jam5v/fr1+uuvv1S+fHktWrRIDz/8cF6XdNc++ugjWa3WvC4DABxCEAOAQiApKUk1atTItf1du3ZNVqtVHh4eubbPO+Xm5iY3t7z7z1nVqlX19NNP59nxHbVw4ULVr19fPXr00GuvvaaLFy/Kx8cnr8u6K+7u7nldAgA4jFsTASCfio2Nla+vr06cOKF27drJ19dXwcHBGjJkiDIzMyVJ8fHxslgsOnLkiL7++mvbrXN//PGHpOsBrXfv3ipZsqS8vLxUp04dzZ8/3+44f/zxhywWiyZNmqRp06apUqVK8vT01IEDB2zPP/388896+umnFRAQoODgYL3xxhsyDEPHjx9X27Zt5e/vr5CQEE2ePNlu3+np6RoxYoQaNGiggIAA+fj4qGnTpvruu+/sjh8cHCxJGj16tO0cRo0aJSnrZ7CuXbumt956y1Zr+fLl9dprr+nq1at2/cqXL69HH31UmzdvVsOGDeXl5aWKFSvqk08+ueufT3ZyUt+gQYNUrFgxGYZha3vppZdksVg0Y8YMW9upU6dksVj0wQcf3Pa4ly9f1v/+9z917txZnTp10uXLl/XFF1/c1C8n19YNkyZNUpMmTVSsWDF5e3urQYMGWr58ebZ1/P7777JYLJo6depN67Zu3SqLxaJPP/1UknThwgW9/PLLKl++vDw9PVWiRAk9+OCD2r17t129/3xGbMmSJWrQoIH8/Pzk7++v2rVra/r06bf9jgDALAQxAMjHMjMzFRMTo2LFimnSpEmKiorS5MmT9eGHH0qSwsPDtWDBAhUvXlx169bVggULtGDBAgUHB+vy5ctq3ry5FixYoK5du2rixIkKCAhQbGxsln9hnTt3rmbOnKm+fftq8uTJCgoKsq178sknZbVaNW7cODVq1Ehvv/22pk2bpgcffFClS5fW+PHjVblyZQ0ZMkQbN260bZeamqo5c+aoefPmGj9+vEaNGqXTp08rJiZGe/bskSQFBwfbQsbjjz9uO4f27dvf8nvp06ePRowYofr162vq1KmKiorS2LFj1blz55v6/vrrr+rYsaMefPBBTZ48WUWLFlVsbKz279+fo5/BlStXdObMGbvln4HvTupr2rSpzp07Z1fHpk2b5OLiok2bNtm1SVKzZs1uW+uXX36ptLQ0de7cWSEhIWrevLkWLVqUZd/bXVs3TJ8+XfXq1dObb76pd955R25ubnriiSf09ddf37KOihUr6r777svy2IsWLZKfn5/atm0rSXruuef0wQcfqEOHDnr//fc1ZMgQeXt76+DBg7fc/9q1a9WlSxcVLVpU48eP17hx49S8eXNt2bLltt8RAJjGAAD8682dO9eQZOzcudPW1qNHD0OS8eabb9r1rVevntGgQQO7tnLlyhmtW7e2a5s2bZohyVi4cKGtLT093YiMjDR8fX2N1NRUwzAM48iRI4Ykw9/f30hKSrLbx8iRIw1JRt++fW1t165dM8qUKWNYLBZj3Lhxtvbz588b3t7eRo8ePez6Xr161W6f58+fN0qWLGn06tXL1nb69GlDkjFy5MibvpsbNdywZ88eQ5LRp08fu35DhgwxJBnr16+3+14kGRs3brS1JSUlGZ6ensbgwYNvOtY/ScpymTt37l3Xl5SUZEgy3n//fcMwDCM5OdlwcXExnnjiCaNkyZK27fr3728EBQUZVqv1tvU++uijxn333Wf7/OGHHxpubm43/VwdubYuXbpk9zk9Pd2oVauW0aJFC7v2cuXK2f3sZ8+ebUgyDh48aLdt8eLF7foFBAQYL7zwQrbn1aNHD6NcuXK2zwMGDDD8/f2Na9euZbsdAOQlRsQAIJ977rnn7D43bdpUv//++223W716tUJCQtSlSxdbm7u7u/r376+0tDRt2LDBrn+HDh1stwj+U58+fWx/dnV1VUREhAzDUO/evW3tgYGBqlatml1trq6utufMrFarzp07p2vXrikiIsLu1jNHrF69WtL1W/v+bvDgwZJ000hNjRo11LRpU9vn4ODgm+rMTtu2bbV27Vq7JSYm5q7rCw4OVvXq1W0jiFu2bJGrq6uGDh2qU6dO6ZdffpF0fUTs/vvvv+0U+WfPntW3335r9/Pu0KGDLBaLPvvssyy3ycm19feJSc6fP6+UlBQ1bdr0tj+/Tp06ycvLy25U7Ntvv9WZM2fsnrkLDAzU9u3bdfLkyWz393eBgYG6ePGi1q5dm+NtAMBsBDEAyMe8vLxuCkdFixbV+fPnb7vt0aNHVaVKFbm42P+nIDw83Lb+7ypUqHDLfZUtW9buc0BAgLy8vFS8ePGb2v9Z2/z583XPPffIy8tLxYoVU3BwsL7++mulpKTc9hyycvToUbm4uKhy5cp27SEhIQoMDLzpvP5Zu5Tz71CSypQpo+joaLulVKlSuVJf06ZNbbcebtq0SREREYqIiFBQUJA2bdqk1NRU7d271y5I3srSpUuVkZGhevXq6ddff9Wvv/6qc+fOqVGjRlneIpjTa2vVqlVq3LixvLy8FBQUZLuV9HY/v8DAQD322GNavHixrW3RokUqXbq0WrRoYWubMGGC9u3bp7CwMDVs2FCjRo26bUju16+fqlatqocfflhlypRRr169tGbNmmy3AQCzEcQAIB9zdXU17VjZTcmeVR23qs342+QTCxcuVGxsrCpVqqT//ve/WrNmjdauXasWLVrc9XTkOX2Jck7qdIac1Hf//ffrxIkT+v3337Vp0yY1bdpUFotF999/vzZt2qStW7fKarXmKIjdCFv33XefqlSpYls2b96sbdu23RRucnJtbdq0SW3atJGXl5fef/99rV69WmvXrtVTTz2Vo++ve/fu+v3337V161ZduHBBX375pbp06WL3Pwc6deqk33//XTNnzlRoaKgmTpyomjVrZvsOtBIlSmjPnj368ssv1aZNG3333Xd6+OGH1aNHj9vWBABmYfp6ACikypUrpx9//FFWq9XuL76HDh2yrXe25cuXq2LFilqxYoVdMPnn+85yGqqk63VbrVb98ssvttE96frsgsnJyaacV3Ycqe9GwFq7dq127txpe19as2bN9MEHHyg0NFQ+Pj5q0KBBtsc8cuSItm7dqhdffFFRUVF266xWq7p166bFixfr9ddfd+hcPv/8c3l5eenbb7+Vp6enrX3u3Lk52r5Vq1YKDg7WokWL1KhRI126dCnLl42XKlVK/fr1U79+/ZSUlKT69etrzJgx2b4DzcPDQ4899pgee+wxWa1W9evXT7Nnz9Ybb7xx02gkAOQFRsQAoJB65JFHlJiYqKVLl9rarl27ppkzZ8rX1/emv7A7w41Rl7+Pnmzfvl3btm2z61ekSBFJUnJy8m33+cgjj0iSpk2bZtc+ZcoUSVLr1q3vtNxc4Uh9FSpUUOnSpTV16lRlZGTovvvuk3Q9oP32229avny5GjdufNv3qN0YDXvllVfUsWNHu6VTp06Kioq65eyJ2XF1dZXFYrGb0v6PP/7QypUrc7S9m5ubunTpos8++0zz5s1T7dq1dc8999jWZ2Zm3nSLY4kSJRQaGprtzJRnz561++zi4mLb7+1mtAQAszAiBgCFVN++fTV79mzFxsYqISFB5cuX1/Lly7VlyxZNmzZNfn5+Tq/h0Ucf1YoVK/T444+rdevWOnLkiGbNmqUaNWooLS3N1s/b21s1atTQ0qVLVbVqVQUFBalWrVqqVavWTfusU6eOevTooQ8//FDJycmKiorSjh07NH/+fLVr104PPPCA088rO47W17RpUy1ZskS1a9dW0aJFJUn169eXj4+Pfv75Zz311FO3PeaiRYtUt25dhYWFZbm+TZs2eumll7R7927Vr18/x+fSunVrTZkyRa1atdJTTz2lpKQkvffee6pcubJ+/PHHHO2je/fumjFjhr777juNHz/ebt2FCxdUpkwZdezYUXXq1JGvr6/WrVunnTt33vROur/r06ePzp07pxYtWqhMmTI6evSoZs6cqbp169qNQgJAXmJEDAAKKW9vb8XHx6tr166aP3++Bg8erHPnzmnu3LkaMGCAKTXExsbqnXfe0d69e9W/f399++23WrhwoSIiIm7qO2fOHJUuXVoDBw5Uly5dsn1p8Jw5czR69Gjt3LlTL7/8stavX6/hw4dryZIlzjydHHOkvhu3J95///22Njc3N0VGRtqtv5Xdu3fr0KFDeuyxx27Z58a6hQsXOnQeLVq00H//+18lJibq5Zdf1qeffqrx48fr8ccfz/E+GjRooJo1a8rFxUVdu3a1W1ekSBH169dPe/bs0ciRIzVw4EAdPnxY77///k2zTv7d008/bXturV+/fpo/f76efPJJffPNNzdNTgMAecViOPtpZAAAgGzUq1dPQUFBiouLy+tSAMA0/G8hAACQZ3bt2qU9e/aoe/fueV0KAJiKETEAAGC6ffv2KSEhQZMnT9aZM2f0+++/y8vLK6/LAgDTMCIGAABMt3z5cvXs2VMZGRn69NNPCWEACh1GxAAAAADAZIyIAQAAAIDJCGIAAAAAYDJe6JwLrFarTp48KT8/P1kslrwuBwAAAEAeMQxDFy5cUGhoaLbvLiSI5YKTJ08qLCwsr8sAAAAA8C9x/PhxlSlT5pbrCWK5wM/PT9L1L9vf3z+PqwEAAACQV1JTUxUWFmbLCLdCEMsFN25H9Pf3J4gBAAAAuO0jS0zWAQAAAAAmI4gBAAAAgMkIYgAAAABgMp4RAwAAgNMYhqFr164pMzMzr0sBcoWrq6vc3Nzu+rVVBDEAAAA4RXp6uv766y9dunQpr0sBclWRIkVUqlQpeXh43PE+CGIAAADIdVarVUeOHJGrq6tCQ0Pl4eFx1yMIQF4zDEPp6ek6ffq0jhw5oipVqmT70ubsEMQAAACQ69LT02W1WhUWFqYiRYrkdTlArvH29pa7u7uOHj2q9PR0eXl53dF+mKwDAAAATnOnowXAv1luXNf8mwEAAAAAJiOIAQAAAIDJCGIAAACAgywWi1auXHlX+4iNjVW7du1sn5s3b66XX375rvZZWM2bN0+BgYF5XYZDCGIAAADA35w+fVrPP/+8ypYtK09PT4WEhCgmJkZbtmzJ69Jy1ahRo1S3bt28LiNH4uPjZbFYblpef/31vC7tjjFrIgAAAPA3HTp0UHp6uubPn6+KFSvq1KlTiouL09mzZ/O6tAIvPT0923dzHT58WP7+/rbPvr6+ZpTlFIyIAQAAwBSGYehS+rU8WQzDyFGNycnJ2rRpk8aPH68HHnhA5cqVU8OGDTV8+HC1adPGru+ZM2f0+OOPq0iRIqpSpYq+/PJL27rMzEz17t1bFSpUkLe3t6pVq6bp06c79H2dP39e3bt3V9GiRVWkSBE9/PDD+uWXX2zfZXBwsJYvX27rX7duXZUqVcr2efPmzfL09LzjF2ovWLBAERER8vPzU0hIiJ566iklJSXZjl+5cmVNmjTJbps9e/bIYrHo119/lXT9++zTp4+Cg4Pl7++vFi1aaO/evbb+N0bl5syZowoVKtx2KvgSJUooJCTEtmQXxD744ANVqlRJHh4eqlatmhYsWGBbN2TIED366KO2z9OmTZPFYtGaNWtsbZUrV9acOXNy8E3dGUbEAAAAYIrLGZmqMeLbPDn2gTdjVMTj9n/19fX1la+vr1auXKnGjRvL09Pzln1Hjx6tCRMmaOLEiZo5c6a6du2qo0ePKigoSFarVWXKlNGyZctUrFgxbd26VX379lWpUqXUqVOnHNUcGxurX375RV9++aX8/f316quv6pFHHtGBAwfk7u6uZs2aKT4+Xh07dtT58+d18OBBeXt769ChQ6pevbo2bNige++9947f45aRkaG33npL1apVU1JSkgYNGqTY2FitXr1aFotFvXr10ty5czVkyBDbNnPnzlWzZs1UuXJlSdITTzwhb29vffPNNwoICNDs2bPVsmVL/fzzzwoKCpIk/frrr/r888+1YsUKubq63lGt//S///1PAwYM0LRp0xQdHa1Vq1apZ8+eKlOmjB544AFFRUVpzpw5yszMlKurqzZs2KDixYsrPj5erVq10okTJ/Tbb7+pefPmuVJPVhgRAwAAAP4/Nzc3zZs3T/Pnz1dgYKDuu+8+vfbaa/rxxx9v6hsbG6suXbqocuXKeuedd5SWlqYdO3ZIktzd3TV69GhFRESoQoUK6tq1q3r27KnPPvssR3XcCGBz5sxR06ZNVadOHS1atEgnTpywTRLSvHlzxcfHS5I2btyoevXq2bXFx8crKirqjr+LXr166eGHH1bFihXVuHFjzZgxQ998843S0tJs53/48GHbOWdkZGjx4sXq1auXpOsjcjt27NCyZcsUERGhKlWqaNKkSQoMDLQbyUtPT9cnn3yievXq6Z577sm2pjJlytjCsq+v7y1vF500aZJiY2PVr18/Va1aVYMGDVL79u1tI3hNmzbVhQsX9MMPP8gwDG3cuFGDBw+2++5Kly5tC5TOwIgYAAAATOHt7qoDb8bk2bFzqkOHDmrdurU2bdqk77//Xt98840mTJigOXPmKDY21tbv76HBx8dH/v7+tlv3JOm9997Txx9/rGPHjuny5ctKT0/P8eQYBw8elJubmxo1amRrK1asmKpVq6aDBw9KkqKiojRgwACdPn1aGzZsUPPmzRUSEqL4+Hj17t1bW7du1SuvvJLj8/6nhIQEjRo1Snv37tX58+dltVolSceOHVONGjUUGhqq1q1b6+OPP1bDhg311Vdf6erVq3riiSckSXv37lVaWpqKFStmt9/Lly/rt99+s30uV66cgoODc1TTpk2b5OfnZ/tctGjRLPsdPHhQffv2tWu77777bLeHBgYGqk6dOoqPj5eHh4c8PDzUt29fjRw5UmlpadqwYcNdhdicIIgBAADAFBaLJUe3B/4beHl56cEHH9SDDz6oN954Q3369NHIkSPtgpi7u7vdNhaLxRZWlixZoiFDhmjy5MmKjIyUn5+fJk6cqO3bt+dajbVr11ZQUJA2bNigDRs2aMyYMQoJCdH48eO1c+dOZWRkqEmTJne074sXLyomJkYxMTFatGiRgoODdezYMcXExCg9Pd3Wr0+fPurWrZumTp2quXPn6sknn7TdCpmWlqZSpUrZRpn+7u9Tzfv4+OS4rgoVKuTaNPU3Rg89PT0VFRWloKAghYeHa/PmzdqwYYMGDx6cK8e5lfzxbwIAAACQh2rUqOHQe8O2bNmiJk2aqF+/fra2v48C3U54eLiuXbum7du328LU2bNndfjwYdWoUUPS9eDXtGlTffHFF9q/f7/uv/9+FSlSRFevXtXs2bMVERHhUMj5u0OHDuns2bMaN26cwsLCJEm7du26qd8jjzwiHx8fffDBB1qzZo02btxoW1e/fn0lJibKzc1N5cuXv6M67lR4eLi2bNmiHj162Nq2bNli++6k6yOKH3/8sdzc3NSqVStJ18PZp59+qp9//tmpz4dJBDEAAADA5uzZs3riiSfUq1cv3XPPPfLz89OuXbs0YcIEtW3bNsf7qVKlij755BN9++23qlChghYsWKCdO3eqQoUKOd6+bdu2euaZZzR79mz5+flp2LBhKl26tF0dzZs31+DBgxUREWGbQbBZs2ZatGiRhg4detvjXL58WXv27LFr8/PzU9myZeXh4aGZM2fqueee0759+/TWW2/dtL2rq6tiY2M1fPhwValSRZGRkbZ10dHRioyMVLt27TRhwgRVrVpVJ0+e1Ndff63HH39cEREROfou7sTQoUPVqVMn1atXT9HR0frqq6+0YsUKrVu3ztanWbNmunDhglatWqVx48ZJuv59duzYUaVKlVLVqlWdVp/EZB0AAACAja+vrxo1aqSpU6eqWbNmqlWrlt544w0988wzevfdd3O8n2effVbt27fXk08+qUaNGuns2bN2o2M5MXfuXDVo0ECPPvqoIiMjZRiGVq9ebXdLZFRUlDIzM+1Gb5o3b35T2638/PPPqlevnt3y7LPPKjg4WPPmzdOyZctUo0YNjRs37qap6m/o3bu30tPT1bNnT7t2i8Wi1atXq1mzZurZs6eqVq2qzp076+jRoypZsqRD34Wj2rVrp+nTp2vSpEmqWbOmZs+erblz59p9J0WLFlXt2rUVHBys6tWrS7oezqxWq9OfD5Mki5HTlyrgllJTUxUQEKCUlBS7F8wBAAAUVleuXNGRI0dy9G4o5G+bNm1Sy5Ytdfz4cacHrH+L7K7vnGYDbk0EAAAA4LCrV6/q9OnTGjVqlJ544olCE8JyC7cmAgAAAHDYp59+qnLlyik5OVkTJkzI63LyHYIYAAAAAIfFxsYqMzNTCQkJKl26dF6Xk+8QxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAQJ4ZNWqU6tatm9dlmI4gBgAAAPxNbGysLBaLLBaL3N3dVbJkST344IP6+OOPZbVa87o8SddrbNeuXV6XkSPz5s2zfZ9/X+bMmZPXpeUpt7wuAAAAAPi3adWqlebOnavMzEydOnVKa9as0YABA7R8+XJ9+eWXcnPjr9H/lJ6eLg8PjyzX+fv76/Dhw3ZtAQEBZpT1r8WIGAAAAMxhGFL6xbxZDMOhUj09PRUSEqLSpUurfv36eu211/TFF1/om2++0bx582z9kpOT1adPHwUHB8vf318tWrTQ3r177fb1xRdfqH79+vLy8lLFihU1evRoXbt2zbbeYrHogw8+0MMPPyxvb29VrFhRy5cvv6uvesqUKapdu7Z8fHwUFhamfv36KS0tTZJ08eJF+fv733SMlStXysfHRxcuXJAkHT9+XJ06dVJgYKCCgoLUtm1b/fHHH7b+N0blxowZo9DQUFWrVu2W9VgsFoWEhNgt3t7eWfa1Wq168803VaZMGXl6eqpu3bpas2aNbX3Hjh314osv2j6//PLLslgsOnTokKTrgdDHx0fr1q1z7EszGVEeAAAA5si4JL0TmjfHfu2k5OFzV7to0aKF6tSpoxUrVqhPnz6SpCeeeELe3t765ptvFBAQoNmzZ6tly5b6+eefFRQUpE2bNql79+6aMWOGmjZtqt9++019+/aVJI0cOdK27zfeeEPjxo3T9OnTtWDBAnXu3Fk//fSTwsPD76hWFxcXzZgxQxUqVNDvv/+ufv366ZVXXtH7778vHx8fde7cWXPnzlXHjh1t29z47Ofnp4yMDMXExCgyMlKbNm2Sm5ub3n77bbVq1Uo//vijbeQrLi5O/v7+Wrt27Z1+rTeZPn26Jk+erNmzZ6tevXr6+OOP1aZNG+3fv19VqlRRVFSUZs+ebeu/YcMGFS9eXPHx8apevbp27typjIwMNWnSJNdqcgZGxAAAAIAcql69um1UaPPmzdqxY4eWLVumiIgIValSRZMmTVJgYKBttGn06NEaNmyYevTooYoVK+rBBx/UW2+9ZRckpOuBrk+fPqpatareeustRUREaObMmXdc58svv6wHHnhA5cuXV4sWLfT222/rs88+s63v06ePvv32W/3111+SpKSkJK1evVq9evWSJC1dulRWq1Vz5sxR7dq1FR4errlz5+rYsWOKj4+37cfHx0dz5sxRzZo1VbNmzVvWk5KSIl9fX9sSEhJyy76TJk3Sq6++qs6dO6tatWoaP3686tatq2nTpkmSmjdvrgMHDuj06dM6f/68Dhw4oAEDBtjqio+P17333qsiRYrc4bdnDkbEAAAAYA73ItdHpvLq2LnAMAxZLBZJ0t69e5WWlqZixYrZ9bl8+bJ+++03W58tW7ZozJgxtvWZmZm6cuWKLl26ZAsLkZGRdvuIjIzUnj177rjOdevWaezYsTp06JBSU1N17do1u2M2bNhQNWvW1Pz58zVs2DAtXLhQ5cqVU7NmzWx1//rrr/Lz87Pb75UrV2znJkm1a9e+5XNhf+fn56fdu3fbPru4ZD0elJqaqpMnT+q+++6za7/vvvtst3zWqlVLQUFB2rBhgzw8PFSvXj09+uijeu+99yRdHyFr3rz57b+kPEYQAwAAgDkslru+PTCvHTx4UBUqVJAkpaWlqVSpUnYjRDcEBgba+owePVrt27e/qY+Xl5dTavzjjz/06KOP6vnnn9eYMWMUFBSkzZs3q3fv3kpPT7eFvz59+ui9997TsGHDNHfuXPXs2dMWMtPS0tSgQQMtWrTopv0HBwfb/uzjk7Ofp4uLiypXrpwLZ3f9ebNmzZopPj5enp6eat68ue655x5dvXpV+/bt09atWzVkyJBcOZYzEcQAAACAHFi/fr1++uknDRw4UJJUv359JSYmys3NTeXLl89ym/r16+vw4cO3DSHff/+9unfvbve5Xr16d1RnQkKCrFarJk+ebBt5+vttiTc8/fTTeuWVVzRjxgwdOHBAPXr0sKt76dKlKlGihPz9/e+ojjvh7++v0NBQbdmyRVFRUbb2LVu2qGHDhrbPUVFR+uijj+Tp6akxY8bIxcVFzZo108SJE3X16tWbRtT+jQhiAAAAwD9cvXpViYmJdtPXjx07Vo8++qgtMEVHRysyMlLt2rXThAkTVLVqVZ08eVJff/21Hn/8cUVERGjEiBF69NFHVbZsWXXs2FEuLi7au3ev9u3bp7ffftt2vBvPmd1///1atGiRduzYof/+97/Z1piSknLT7YvFihVT5cqVlZGRoZkzZ+qxxx7Tli1bNGvWrJu2L1q0qNq3b6+hQ4fqoYceUpkyZWzrunbtqokTJ6pt27a2GQyPHj2qFStW6JVXXrHrm9uGDh2qkSNHqlKlSqpbt67mzp2rPXv22I3ONW/eXAMHDpSHh4fuv/9+W9uQIUN077335nikLi8RxAAAAIB/WLNmjUqVKiU3NzcVLVpUderU0YwZM9SjRw/bKJPFYtHq1av1n//8Rz179tTp06cVEhKiZs2aqWTJkpKkmJgYrVq1Sm+++abGjx8vd3d3Va9e3Tbr4g2jR4/WkiVL1K9fP5UqVUqffvqpatSokW2N8fHxN42a9e7dW3PmzNGUKVM0fvx4DR8+XM2aNdPYsWPtRtz+3n/x4sW2STpuKFKkiDZu3KhXX31V7du314ULF1S6dGm1bNnS6SNk/fv3V0pKigYPHqykpCTVqFFDX375papUqWLrU7t2bQUGBqpq1ary9fWVdD2IZWZm5ovnwyTJYhgOvlQBN0lNTVVAQIBSUlJMHboFAAD4t7py5YqOHDmiChUqOO1ZqILCYrHof//7n9q1a2f6sRcsWKCBAwfq5MmTOZp0A9dld33nNBswIgYAAAAUMpcuXdJff/2lcePG6dlnnyWE5QHeIwYAAAAUMhMmTFD16tUVEhKi4cOH53U5hRIjYgAAAEAeyosnhUaNGqVRo0aZflz8H0bEAAAAAMBkBDEAAAA4DfPCoSDKjeuaIAYAAIBc5+7uLun6pBBAQXPjur5xnd8JnhEDAABArnN1dVVgYKCSkpIkXX8vlcViyeOqgLtjGIYuXbqkpKQkBQYGytXV9Y73RRADAACAU4SEhEiSLYwBBUVgYKDt+r5TBDEAAAA4hcViUalSpVSiRAllZGTkdTlArnB3d7+rkbAbCGIAAABwKldX11z5iytQkDBZBwAAAACYjCAGAAAAACYjiAEAAACAyfJdEHvvvfdUvnx5eXl5qVGjRtqxY0e2/ZctW6bq1avLy8tLtWvX1urVq2/Z97nnnpPFYtG0adNyuWoAAAAA+D/5KogtXbpUgwYN0siRI7V7927VqVNHMTExt5wSdevWrerSpYt69+6tH374Qe3atVO7du20b9++m/r+73//0/fff6/Q0FBnnwYAAACAQi5fBbEpU6bomWeeUc+ePVWjRg3NmjVLRYoU0ccff5xl/+nTp6tVq1YaOnSowsPD9dZbb6l+/fp699137fqdOHFCL730khYtWnRXb8cGAAAAgJzIN0EsPT1dCQkJio6OtrW5uLgoOjpa27Zty3Kbbdu22fWXpJiYGLv+VqtV3bp109ChQ1WzZs0c1XL16lWlpqbaLQAAAACQU/kmiJ05c0aZmZkqWbKkXXvJkiWVmJiY5TaJiYm37T9+/Hi5ubmpf//+Oa5l7NixCggIsC1hYWEOnAkAAACAwi7fBDFnSEhI0PTp0zVv3jxZLJYcbzd8+HClpKTYluPHjzuxSgAAAAAFTb4JYsWLF5erq6tOnTpl137q1CmFhIRkuU1ISEi2/Tdt2qSkpCSVLVtWbm5ucnNz09GjRzV48GCVL1/+lrV4enrK39/fbgEAAACAnMo3QczDw0MNGjRQXFycrc1qtSouLk6RkZFZbhMZGWnXX5LWrl1r69+tWzf9+OOP2rNnj20JDQ3V0KFD9e233zrvZAAAAAAUam55XYAjBg0apB49eigiIkINGzbUtGnTdPHiRfXs2VOS1L17d5UuXVpjx46VJA0YMEBRUVGaPHmyWrdurSVLlmjXrl368MMPJUnFihVTsWLF7I7h7u6ukJAQVatWzdyTAwAAAFBo5Ksg9uSTT+r06dMaMWKEEhMTVbduXa1Zs8Y2IcexY8fk4vJ/g3xNmjTR4sWL9frrr+u1115TlSpVtHLlStWqVSuvTgEAAAAAZDEMw8jrIvK71NRUBQQEKCUlhefFAAAAgEIsp9kg3zwjBgAAAAAFBUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwWb4LYu+9957Kly8vLy8vNWrUSDt27Mi2/7Jly1S9enV5eXmpdu3aWr16tW1dRkaGXn31VdWuXVs+Pj4KDQ1V9+7ddfLkSWefBgAAAIBCLF8FsaVLl2rQoEEaOXKkdu/erTp16igmJkZJSUlZ9t+6dau6dOmi3r1764cfflC7du3Url077du3T5J06dIl7d69W2+88YZ2796tFStW6PDhw2rTpo2ZpwUAAACgkLEYhmHkdRE51ahRI91777169913JUlWq1VhYWF66aWXNGzYsJv6P/nkk7p48aJWrVpla2vcuLHq1q2rWbNmZXmMnTt3qmHDhjp69KjKli2bo7pSU1MVEBCglJQU+fv738GZAQAAACgIcpoN8s2IWHp6uhISEhQdHW1rc3FxUXR0tLZt25blNtu2bbPrL0kxMTG37C9JKSkpslgsCgwMvGWfq1evKjU11W4BAAAAgJzKN0HszJkzyszMVMmSJe3aS5YsqcTExCy3SUxMdKj/lStX9Oqrr6pLly7ZptexY8cqICDAtoSFhTl4NgAAAAAKs3wTxJwtIyNDnTp1kmEY+uCDD7LtO3z4cKWkpNiW48ePm1QlAAAAgILALa8LyKnixYvL1dVVp06dsms/deqUQkJCstwmJCQkR/1vhLCjR49q/fr1t33Oy9PTU56enndwFgAAAACQj0bEPDw81KBBA8XFxdnarFar4uLiFBkZmeU2kZGRdv0lae3atXb9b4SwX375RevWrVOxYsWccwIAAAAA8P/lmxExSRo0aJB69OihiIgINWzYUNOmTdPFixfVs2dPSVL37t1VunRpjR07VpI0YMAARUVFafLkyWrdurWWLFmiXbt26cMPP5R0PYR17NhRu3fv1qpVq5SZmWl7fiwoKEgeHh55c6IAAAAACrR8FcSefPJJnT59WiNGjFBiYqLq1q2rNWvW2CbkOHbsmFxc/m+Qr0mTJlq8eLFef/11vfbaa6pSpYpWrlypWrVqSZJOnDihL7/8UpJUt25du2N99913at68uSnnBQAAAKBwyVfvEfu34j1iAAAAAKQC+B4xAAAAACgoCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMncHN2gbNmyat68uaKiotS8eXNVqlTJGXUBAAAAQIHl8IjYO++8Iy8vL40fP15VqlRRWFiYnn76aX300Uf65ZdfnFEjAAAAABQoFsMwjDvd+K+//tKGDRu0atUqLV26VFarVZmZmblZX76QmpqqgIAApaSkyN/fP6/LAQAAAJBHcpoNHL41UZIuXbqkzZs3Kz4+Xt99951++OEH1apVS82bN7/TegEAAACg0HA4iDVp0kQ//PCDwsPD1bx5cw0bNkzNmjVT0aJFnVEfAAAAABQ4Dj8jdujQIfn4+Kh69eqqXr26wsPDCWEAAAAA4ACHg9jZs2e1fv16NW7cWN9++63uu+8+lS5dWk899ZQ++ugjZ9QIAAAAAAXKXU3WYRiGEhIS9O6772rRokVM1sFkHQAAAECh5rTJOnbv3q34+HjFx8dr8+bNunDhgmrXrq2XXnpJUVFRd1U0AAAAABQGDgexhg0bql69eoqKitIzzzyjZs2aKSAgwBm1AQAAAECB5HAQO3fuHLffAQAAAMBdcDiI3QhhCQkJOnjwoCSpRo0aql+/fu5WBgAAAAAFlMNBLCkpSU8++aQ2bNigwMBASVJycrIeeOABLVmyRMHBwbldIwAAAAAUKA5PX//SSy8pLS1N+/fv17lz53Tu3Dnt27dPqamp6t+/vzNqBAAAAIACxeHp6wMCArRu3Trde++9du07duzQQw89pOTk5NysL19g+noAAAAAUs6zgcMjYlarVe7u7je1u7u7y2q1Oro7AAAAACh0HA5iLVq00IABA3Ty5Elb24kTJzRw4EC1bNkyV4sDAAAAgILI4SD27rvvKjU1VeXLl1elSpVUqVIlVahQQampqZo5c6YzagQAAACAAsXhWRPDwsK0e/durVu3TocOHZIkhYeHKzo6OteLAwAAAICCyOHJOnAzJusAAAAAIOU8G+RoRGzGjBk5PjBT2AMAAABA9nI0IlahQoWc7cxi0e+//37XReU3jIgBAAAAkHJ5ROzIkSO5VhgAAAAAFHY5njWRd4QBAAAAQO7IcRBzd3dXUlKS7fPQoUN17tw5pxQFAAAAAAVZjoPYPx8lmz17tpKTk3O7HgAAAAAo8Bx+ofMNzHoPAAAAAHfmjoMYAAAAAODO5GjWxBtGjBihIkWKSJLS09M1ZswYBQQE2PWZMmVK7lUHAAAAAAVQjoNYs2bNdPjwYdvnJk2a3PTOMIvFknuVAQAAAEABleMgFh8f78QyAAAAAKDw4BkxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwmUPvEbshOTlZO3bsUFJSkqxWq9267t2750phAAAAAFBQORzEvvrqK3Xt2lVpaWny9/e3e3eYxWIhiAEAAADAbTh8a+LgwYPVq1cvpaWlKTk5WefPn7ct586dc0aNAAAAAFCgOBzETpw4of79+6tIkSLOqAcAAAAACjyHg1hMTIx27drljFoAAAAAoFBw+Bmx1q1ba+jQoTpw4IBq164td3d3u/Vt2rTJteIAAAAAoCCyGIZhOLKBi8utB9EsFosyMzPvuqj8JjU1VQEBAUpJSZG/v39elwMAAAAgj+Q0Gzg8IvbP6eoBAAAAAI7hhc4AAAAAYLI7CmIbNmzQY489psqVK6ty5cpq06aNNm3alNu1AQAAAECB5HAQW7hwoaKjo1WkSBH1799f/fv3l7e3t1q2bKnFixc7o0YAAAAAKFAcnqwjPDxcffv21cCBA+3ap0yZoo8++kgHDx7M1QLzAybrAAAAACDlPBs4PCL2+++/67HHHrupvU2bNjpy5IijuwMAAACAQsfhIBYWFqa4uLib2tetW6ewsLBcKQoAAAAACjKHp68fPHiw+vfvrz179qhJkyaSpC1btmjevHmaPn16rhcIAAAAAAWNw0Hs+eefV0hIiCZPnqzPPvtM0vXnxpYuXaq2bdvmeoEAAAAAUNDc0fT1jz/+uDZv3qyzZ8/q7Nmz2rx5s2kh7L333lP58uXl5eWlRo0aaceOHdn2X7ZsmapXry4vLy/Vrl1bq1evtltvGIZGjBihUqVKydvbW9HR0frll1+ceQoAAAAACrl89ULnpUuXatCgQRo5cqR2796tOnXqKCYmRklJSVn237p1q7p06aLevXvrhx9+ULt27dSuXTvt27fP1mfChAmaMWOGZs2ape3bt8vHx0cxMTG6cuWKWacFAAAAoJDJ0fT1QUFB+vnnn1W8eHEVLVpUFovlln3PnTuXqwX+XaNGjXTvvffq3XfflSRZrVaFhYXppZde0rBhw27q/+STT+rixYtatWqVra1x48aqW7euZs2aJcMwFBoaqsGDB2vIkCGSpJSUFJUsWVLz5s1T586dc1QX09cDAAAAkHKeDXL0jNjUqVPl5+dn+3N2QcxZ0tPTlZCQoOHDh9vaXFxcFB0drW3btmW5zbZt2zRo0CC7tpiYGK1cuVKSdOTIESUmJio6Otq2PiAgQI0aNdK2bdtuGcSuXr2qq1ev2j6npqbe6WkBAAAAKIRyFMR69Ohh+3NsbKyzasnWmTNnlJmZqZIlS9q1lyxZUocOHcpym8TExCz7JyYm2tbfaLtVn6yMHTtWo0ePdvgcAAAAAEC6g2fEXF1ds3wm6+zZs3J1dc2Vov7thg8frpSUFNty/PjxvC4JAAAAQD7icBC71SNlV69elYeHx10XdCvFixeXq6urTp06Zdd+6tQphYSEZLlNSEhItv1v/NORfUqSp6en/P397RYAAAAAyKkcv0dsxowZkiSLxaI5c+bI19fXti4zM1MbN25U9erVc7/C/8/Dw0MNGjRQXFyc2rVrJ+n6ZB1xcXF68cUXs9wmMjJScXFxevnll21ta9euVWRkpCSpQoUKCgkJUVxcnOrWrSvp+vNe27dv1/PPP++0cwEAAABQuOU4iE2dOlXS9RGxWbNm2d2G6OHhofLly2vWrFm5X+HfDBo0SD169FBERIQaNmyoadOm6eLFi+rZs6ckqXv37ipdurTGjh0rSRowYICioqI0efJktW7dWkuWLNGuXbv04YcfSroeKl9++WW9/fbbqlKliipUqKA33nhDoaGhtrAHAAAAALktx0HsyJEjkqQHHnhAK1asUNGiRZ1W1K08+eSTOn36tEaMGKHExETVrVtXa9assU22cezYMbm4/N/dlk2aNNHixYv1+uuv67XXXlOVKlW0cuVK1apVy9bnlVde0cWLF9W3b18lJyfr/vvv15o1a+Tl5WX6+QEAAAAoHHL0HjFkj/eIAQAAAJBy+T1i//Tnn3/qyy+/1LFjx5Senm63bsqUKXeySwAAAAAoNBwOYnFxcWrTpo0qVqyoQ4cOqVatWvrjjz9kGIbq16/vjBoBAAAAoEBxePr64cOHa8iQIfrpp5/k5eWlzz//XMePH1dUVJSeeOIJZ9QIAAAAAAWKw0Hs4MGD6t69uyTJzc1Nly9flq+vr958802NHz8+1wsEAAAAgILG4SDm4+Njey6sVKlS+u2332zrzpw5k3uVAQAAAEAB5fAzYo0bN9bmzZsVHh6uRx55RIMHD9ZPP/2kFStWqHHjxs6oEQAAAAAKFIeD2JQpU5SWliZJGj16tNLS0rR06VJVqVKFGRMBAAAAIAd4j1gu4D1iAAAAACQnv0fshrS0NFmtVrs2gggAAAAAZM/hyTqOHDmi1q1by8fHRwEBASpatKiKFi2qwMBAFS1a1Bk1AgAAAECB4vCI2NNPPy3DMPTxxx+rZMmSslgszqgLAAAAAAosh4PY3r17lZCQoGrVqjmjHgAAAAAo8By+NfHee+/V8ePHnVELAAAAABQKDo+IzZkzR88995xOnDihWrVqyd3d3W79Pffck2vFAQAAAEBB5HAQO336tH777Tf17NnT1maxWGQYhiwWizIzM3O1QAAAAAAoaBwOYr169VK9evX06aefMlkHAAAAANwBh4PY0aNH9eWXX6py5crOqAcAAAAACjyHJ+to0aKF9u7d64xaAAAAAKBQcHhE7LHHHtPAgQP1008/qXbt2jdN1tGmTZtcKw4AAAAACiKLYRiGIxu4uNx6EK2wTtaRmpqqgIAApaSkyN/fP6/LAQAAAJBHcpoNHB4Rs1qtd1UYAAAAABR2Dj0jlpGRITc3N+3bt89Z9QAAAABAgedQEHN3d1fZsmUL5e2HAAAAAJBbHJ418T//+Y9ee+01nTt3zhn1AAAAAECB5/AzYu+++65+/fVXhYaGqly5cvLx8bFbv3v37lwrDgAAAAAKIoeDWLt27ZxQBgAAAAAUHg5PX4+bMX09AAAAAMmJ09ffkJCQoIMHD0qSatasqXr16t3prgAAAACgUHE4iCUlJalz586Kj49XYGCgJCk5OVkPPPCAlixZouDg4NyuEQAAAAAKFIdnTXzppZd04cIF7d+/X+fOndO5c+e0b98+paamqn///s6oEQAAAAAKFIefEQsICNC6det077332rXv2LFDDz30kJKTk3OzvnyBZ8QAAAAASDnPBg6PiFmtVrm7u9/U7u7uLqvV6ujuAAAAAKDQcTiItWjRQgMGDNDJkydtbSdOnNDAgQPVsmXLXC0OAAAAAAoih4PYu+++q9TUVJUvX16VKlVSpUqVVKFCBaWmpmrmzJnOqBEAAAAAChSHZ00MCwvT7t27tW7dOh06dEiSFB4erujo6FwvDgAAAAAKohxN1hEUFKSff/5ZxYsXV69evTR9+nT5+fmZUV++wGQdAAAAAKRcnqwjPT1dqampkqT58+frypUruVMlAAAAABRCObo1MTIyUu3atVODBg1kGIb69+8vb2/vLPt+/PHHuVogAAAAABQ0OQpiCxcu1NSpU/Xbb7/JYrEoJSWFUTEAAAAAuEMOv9C5QoUK2rVrl4oVK+asmvIdnhEDAAAAIOU8Gzg8a+KRI0fuqjAAAAAAKOwcDmKSFBcXp7i4OCUlJclqtdqt4xkxAAAAAMiew0Fs9OjRevPNNxUREaFSpUrJYrE4oy4AAAAAKLAcDmKzZs3SvHnz1K1bN2fUAwAAAAAFXo7eI/Z36enpatKkiTNqAQAAAIBCweEg1qdPHy1evNgZtQAAAABAoeDwrYlXrlzRhx9+qHXr1umee+6Ru7u73fopU6bkWnEAAAAAUBA5HMR+/PFH1a1bV5K0b98+u3VM3AEAAAAAt+dwEPvuu++cUQcAAAAAFBoOPyMGAAAAALg7OR4Ra9++fY76rVix4o6LAQAAAIDCIMdBLCAgwJl1AAAAAEChkeMgNnfuXGfWAQAAAACFBs+IAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmyzdB7Ny5c+ratav8/f0VGBio3r17Ky0tLdttrly5ohdeeEHFihWTr6+vOnTooFOnTtnW7927V126dFFYWJi8vb0VHh6u6dOnO/tUAAAAABRy+SaIde3aVfv379fatWu1atUqbdy4UX379s12m4EDB+qrr77SsmXLtGHDBp08eVLt27e3rU9ISFCJEiW0cOFC7d+/X//5z380fPhwvfvuu84+HQAAAACFmMUwDCOvi7idgwcPqkaNGtq5c6ciIiIkSWvWrNEjjzyiP//8U6GhoTdtk5KSouDgYC1evFgdO3aUJB06dEjh4eHatm2bGjdunOWxXnjhBR08eFDr16/PcX2pqakKCAhQSkqK/P397+AMAQAAABQEOc0G+WJEbNu2bQoMDLSFMEmKjo6Wi4uLtm/fnuU2CQkJysjIUHR0tK2tevXqKlu2rLZt23bLY6WkpCgoKCjbeq5evarU1FS7BQAAAAByKl8EscTERJUoUcKuzc3NTUFBQUpMTLzlNh4eHgoMDLRrL1my5C232bp1q5YuXXrbWx7Hjh2rgIAA2xIWFpbzkwEAAABQ6OVpEBs2bJgsFku2y6FDh0ypZd++fWrbtq1Gjhyphx56KNu+w4cPV0pKim05fvy4KTUCAAAAKBjc8vLggwcPVmxsbLZ9KlasqJCQECUlJdm1X7t2TefOnVNISEiW24WEhCg9PV3Jycl2o2KnTp26aZsDBw6oZcuW6tu3r15//fXb1u3p6SlPT8/b9gMAAACArORpEAsODlZwcPBt+0VGRio5OVkJCQlq0KCBJGn9+vWyWq1q1KhRlts0aNBA7u7uiouLU4cOHSRJhw8f1rFjxxQZGWnrt3//frVo0UI9evTQmDFjcuGsAAAAACB7+WLWREl6+OGHderUKc2aNUsZGRnq2bOnIiIitHjxYknSiRMn1LJlS33yySdq2LChJOn555/X6tWrNW/ePPn7++ull16SdP1ZMOn67YgtWrRQTEyMJk6caDuWq6trjgLiDcyaCAAAAEDKeTbI0xExRyxatEgvvviiWrZsKRcXF3Xo0EEzZsywrc/IyNDhw4d16dIlW9vUqVNtfa9evaqYmBi9//77tvXLly/X6dOntXDhQi1cuNDWXq5cOf3xxx+mnBcAAACAwiffjIj9mzEiBgAAAEAqYO8RAwAAAICChCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAAAgMkIYgAAAABgMoIYAAAAAJiMIAYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYLN8EsXPnzqlr167y9/dXYGCgevfurbS0tGy3uXLlil544QUVK1ZMvr6+6tChg06dOpVl37Nnz6pMmTKyWCxKTk52whkAAAAAwHX5Joh17dpV+/fv19q1a7Vq1Spt3LhRffv2zXabgQMH6quvvtKyZcu0YcMGnTx5Uu3bt8+yb+/evXXPPfc4o3QAAAAAsGMxDMPI6yJu5+DBg6pRo4Z27typiIgISdKaNWv0yCOP6M8//1RoaOhN26SkpCg4OFiLFy9Wx44dJUmHDh1SeHi4tm3bpsaNG9v6fvDBB1q6dKlGjBihli1b6vz58woMDMxxfampqQoICFBKSor8/f3v7mQBAAAA5Fs5zQb5YkRs27ZtCgwMtIUwSYqOjpaLi4u2b9+e5TYJCQnKyMhQdHS0ra169eoqW7astm3bZms7cOCA3nzzTX3yySdyccnZ13H16lWlpqbaLQAAAACQU/kiiCUmJqpEiRJ2bW5ubgoKClJiYuItt/Hw8LhpZKtkyZK2ba5evaouXbpo4sSJKlu2bI7rGTt2rAICAmxLWFiYYycEAAAAoFDL0yA2bNgwWSyWbJdDhw457fjDhw9XeHi4nn76aYe3S0lJsS3Hjx93UoUAAAAACiK3vDz44MGDFRsbm22fihUrKiQkRElJSXbt165d07lz5xQSEpLldiEhIUpPT1dycrLdqNipU6ds26xfv14//fSTli9fLkm68bhc8eLF9Z///EejR4/Oct+enp7y9PTMySkCAAAAwE3yNIgFBwcrODj4tv0iIyOVnJyshIQENWjQQNL1EGW1WtWoUaMst2nQoIHc3d0VFxenDh06SJIOHz6sY8eOKTIyUpL0+eef6/Lly7Ztdu7cqV69emnTpk2qVKnS3Z4eAAAAAGQpT4NYToWHh6tVq1Z65plnNGvWLGVkZOjFF19U586dbTMmnjhxQi1bttQnn3yihg0bKiAgQL1799agQYMUFBQkf39/vfTSS4qMjLTNmPjPsHXmzBnb8RyZNREAAAAAHJEvgpgkLVq0SC+++KJatmwpFxcXdejQQTNmzLCtz8jI0OHDh3Xp0iVb29SpU219r169qpiYGL3//vt5UT4AAAAA2OSL94j92/EeMQAAAABSAXuPGAAAAAAUJAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAExGEAMAAAAAkxHEAAAAAMBkBDEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAwGUEMAAAAAEzmltcFFASGYUiSUlNT87gSAAAAAHnpRia4kRFuhSCWCy5cuCBJCgsLy+NKAAAAAPwbXLhwQQEBAbdcbzFuF9VwW1arVSdPnpSfn58sFktel4MspKamKiwsTMePH5e/v39el4N8gGsGjuKagaO4ZuAorpn8wTAMXbhwQaGhoXJxufWTYIyI5QIXFxeVKVMmr8tADvj7+/OLCw7hmoGjuGbgKK4ZOIpr5t8vu5GwG5isAwAAAABMRhADAAAAAJMRxFAoeHp6auTIkfL09MzrUpBPcM3AUVwzcBTXDBzFNVOwMFkHAAAAAJiMETEAAAAAMBlBDAAAAABMRhADAAAAAJMRxAAAAADAZAQxFBjnzp1T165d5e/vr8DAQPXu3VtpaWnZbnPlyhW98MILKlasmHx9fdWhQwedOnUqy75nz55VmTJlZLFYlJyc7IQzgJmccb3s3btXXbp0UVhYmLy9vRUeHq7p06c7+1TgRO+9957Kly8vLy8vNWrUSDt27Mi2/7Jly1S9enV5eXmpdu3aWr16td16wzA0YsQIlSpVSt7e3oqOjtYvv/zizFOAiXLzesnIyNCrr76q2rVry8fHR6GhoerevbtOnjzp7NOAiXL7d8zfPffcc7JYLJo2bVouV41cYwAFRKtWrYw6deoY33//vbFp0yajcuXKRpcuXbLd5rnnnjPCwsKMuLg4Y9euXUbjxo2NJk2aZNm3bdu2xsMPP2xIMs6fP++EM4CZnHG9/Pe//zX69+9vxMfHG7/99puxYMECw9vb25g5c6azTwdOsGTJEsPDw8P4+OOPjf379xvPPPOMERgYaJw6dSrL/lu2bDFcXV2NCRMmGAcOHDBef/11w93d3fjpp59sfcaNG2cEBAQYK1euNPbu3Wu0adPGqFChgnH58mWzTgtOktvXS3JyshEdHW0sXbrUOHTokLFt2zajYcOGRoMGDcw8LTiRM37H3LBixQqjTp06RmhoqDF16lQnnwnuFEEMBcKBAwcMScbOnTttbd98841hsViMEydOZLlNcnKy4e7ubixbtszWdvDgQUOSsW3bNru+77//vhEVFWXExcURxAoAZ18vf9evXz/jgQceyL3iYZqGDRsaL7zwgu1zZmamERoaaowdOzbL/p06dTJat25t19aoUSPj2WefNQzDMKxWqxESEmJMnDjRtj45Odnw9PQ0Pv30UyecAcyU29dLVnbs2GFIMo4ePZo7RSNPOeua+fPPP43SpUsb+/btM8qVK0cQ+xfj1kQUCNu2bVNgYKAiIiJsbdHR0XJxcdH27duz3CYhIUEZGRmKjo62tVWvXl1ly5bVtm3bbG0HDhzQm2++qU8++UQuLvwrUxA483r5p5SUFAUFBeVe8TBFenq6EhIS7H7eLi4uio6OvuXPe9u2bXb9JSkmJsbW/8iRI0pMTLTrExAQoEaNGmV7DeHfzxnXS1ZSUlJksVgUGBiYK3Uj7zjrmrFarerWrZuGDh2qmjVrOqd45Br+VokCITExUSVKlLBrc3NzU1BQkBITE2+5jYeHx03/QStZsqRtm6tXr6pLly6aOHGiypYt65TaYT5nXS//tHXrVi1dulR9+/bNlbphnjNnzigzM1MlS5a0a8/u552YmJht/xv/dGSfyB+ccb3805UrV/Tqq6+qS5cu8vf3z53CkWecdc2MHz9ebm5u6t+/f+4XjVxHEMO/2rBhw2SxWLJdDh065LTjDx8+XOHh4Xr66aeddgzknry+Xv5u3759atu2rUaOHKmHHnrIlGMCKJgyMjLUqVMnGYahDz74IK/Lwb9UQkKCpk+frnnz5sliseR1OcgBt7wuAMjO4MGDFRsbm22fihUrKiQkRElJSXbt165d07lz5xQSEpLldiEhIUpPT1dycrLdKMepU6ds26xfv14//fSTli9fLun6jGeSVLx4cf3nP//R6NGj7/DM4Ax5fb3ccODAAbVs2VJ9+/bV66+/fkfngrxVvHhxubq63jSLalY/7xtCQkKy7X/jn6dOnVKpUqXs+tStWzcXq4fZnHG93HAjhB09elTr169nNKyAcMY1s2nTJiUlJdndwZOZmanBgwdr2rRp+uOPP3L3JHDXGBHDv1pwcLCqV6+e7eLh4aHIyEglJycrISHBtu369etltVrVqFGjLPfdoEEDubu7Ky4uztZ2+PBhHTt2TJGRkZKkzz//XHv37tWePXu0Z88ezZkzR9L1X3YvvPCCE88cdyKvrxdJ2r9/vx544AH16NFDY8aMcd7Jwqk8PDzUoEEDu5+31WpVXFyc3c/77yIjI+36S9LatWtt/StUqKCQkBC7Pqmpqdq+ffst94n8wRnXi/R/IeyXX37RunXrVKxYMeecAEznjGumW7du+vHHH21/Z9mzZ49CQ0M1dOhQffvtt847Gdy5vJ4tBMgtrVq1MurVq2ds377d2Lx5s1GlShW76cj//PNPo1q1asb27dttbc8995xRtmxZY/369cauXbuMyMhIIzIy8pbH+O6775g1sYBwxvXy008/GcHBwcbTTz9t/PXXX7YlKSnJ1HND7liyZInh6elpzJs3zzhw4IDRt29fIzAw0EhMTDQMwzC6detmDBs2zNZ/y5YthpubmzFp0iTj4MGDxsiRI7Ocvj4wMND44osvjB9//NFo27Yt09cXELl9vaSnpxtt2rQxypQpY+zZs8fud8rVq1fz5ByRu5zxO+afmDXx340ghgLj7NmzRpcuXQxfX1/D39/f6Nmzp3HhwgXb+iNHjhiSjO+++87WdvnyZaNfv35G0aJFjSJFihiPP/648ddff93yGASxgsMZ18vIkSMNSTct5cqVM/HMkJtmzpxplC1b1vDw8DAaNmxofP/997Z1UVFRRo8ePez6f/bZZ0bVqlUNDw8Po2bNmsbXX39tt95qtRpvvPGGUbJkScPT09No2bKlcfjwYTNOBSbIzevlxu+grJa//15C/pbbv2P+iSD272YxjP//0AsAAAAAwBQ8IwYAAAAAJiOIAQAAAIDJCGIAAAAAYDKCGAAAAACYjCAGAAAAACYjiAEAAACAyQhiAAAAAGAyghgAAAAAmIwgBgAAAAAmI4gBAAq92NhYtWvXLq/LAAAUIgQxAAD+ZdLT0/O6BACAkxHEAADIxpQpU1S7dm35+PgoLCxM/fr1U1pamiTp4sWL8vf31/Lly+22WblypXx8fHThwgVJ0vHjx9WpUycFBgYqKChIbdu21R9//GHrf2NEbsyYMQoNDVW1atVMOz8AQN4giAEAkA0XFxfNmDFD+/fv1/z587V+/Xq98sorkiQfHx917txZc+fOtdtm7ty56tixo/z8/JSRkaGYmBj5+flp06ZN2rJli3x9fdWqVSu7ka+4uDgdPnxYa9eu1apVq0w9RwCA+SyGYRh5XQQAAHkpNjZWycnJWrly5W37Ll++XM8995zOnDkjSdqxY4eaNGmi48ePq1SpUkpKSlLp0qW1bt06RUVFaeHChXr77bd18OBBWSwWSddvPQwMDNTKlSv10EMPKTY2VmvWrNGxY8fk4eHhzFMFAPxLMCIGAEA21q1bp5YtW6p06dLy8/NTt27ddPbsWV26dEmS1LBhQ9WsWVPz58+XJC1cuFDlypVTs2bNJEl79+7Vr7/+Kj8/P/n6+srX11dBQUG6cuWKfvvtN9txateuTQgDgEKEIAYAwC388ccfevTRR3XPPffo888/V0JCgt577z1J9hNq9OnTR/PmzZN0/bbEnj172ka/0tLS1KBBA+3Zs8du+fnnn/XUU0/Z9uHj42PeiQEA8pxbXhcAAMC/VUJCgqxWqyZPniwXl+v/7/Kzzz67qd/TTz+tV155RTNmzNCBAwfUo0cP27r69etr6dKlKlGihPz9/U2rHQDw78aIGAAAklJSUm4atSpevLgyMjI0c+ZM/f7771qwYIFmzZp107ZFixZV+/btNXToUD300EMqU6aMbV3Xrl1VvHhxtW3bVps2bdKRI0cUHx+v/v37688//zTzFAEA/yIEMQAAJMXHx6tevXp2y4IFCzRlyhSNHz9etWrV0qJFizR27Ngst+/du7fS09PVq1cvu/YiRYpo48aNKlu2rNq3b6/w8HD17t1bV65cYYQMAAoxZk0EACAXLFiwQAMHDtTJkyeZdAMAcFs8IwYAwF24dOmS/vrrL40bN07PPvssIQwAkCPcmggAwF2YMGGCqlevrpCQEA0fPjyvywEA5BPcmggAAAAAJmNEDAAAAABMRhADAAAAAJMRxAAAAADAZAQxAAAAADAZQQwAAAAATEYQAwAAAACTEcQAAAAAwGQEMQAAAAAw2f8DY/V13/8kfV0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoyalty Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loyalty)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 130\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m attention_mask[:, label_positions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    129\u001b[0m handle \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mblock_information_flow(\u001b[38;5;241m0\u001b[39m, attention_mask)\n\u001b[0;32m--> 130\u001b[0m outputs_blocked \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Compute loyalty metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1272\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1272\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1133\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1122\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         output_attentions,\n\u001b[1;32m   1131\u001b[0m     )\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:615\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    613\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 615\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    624\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.10/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[11], line 75\u001b[0m, in \u001b[0;36mLabelWordAnalyzer.block_information_flow.<locals>.attention_hook\u001b[0;34m(module, input_tensor, output_tensor)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattention_hook\u001b[39m(module, input_tensor, output_tensor):\n\u001b[0;32m---> 75\u001b[0m     modified_attention \u001b[38;5;241m=\u001b[39m \u001b[43moutput_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m modified_attention\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "class LabelWordAnalyzer:\n",
    "    def __init__(self, model_name: str = \"gpt2\"):\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def prepare_input(self, demonstrations: List[Dict], query: str) -> torch.Tensor:\n",
    "        \"\"\"Format input with demonstrations and query.\"\"\"\n",
    "        prompt = \"\"\n",
    "        for demo in demonstrations:\n",
    "            prompt += f\"Text: {demo['text']}\\nLabel: {demo['label']}\\n\\n\"\n",
    "        prompt += f\"Text: {query}\\nLabel:\"\n",
    "        \n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        return inputs.to(self.device)\n",
    "\n",
    "    def compute_attention_flow(self, input_ids: torch.Tensor, \n",
    "                             label_positions: List[int]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Compute attention flow metrics for shallow and deep layers.\"\"\"\n",
    "        outputs = self.model(input_ids, output_attentions=True)\n",
    "        attentions = outputs.attentions\n",
    "        \n",
    "        # Track information flow metrics\n",
    "        shallow_flow = self._compute_layer_flow(attentions[:len(attentions)//2], \n",
    "                                              label_positions)\n",
    "        deep_flow = self._compute_layer_flow(attentions[len(attentions)//2:], \n",
    "                                           label_positions)\n",
    "        \n",
    "        return {\n",
    "            \"shallow_flow\": shallow_flow,\n",
    "            \"deep_flow\": deep_flow\n",
    "        }\n",
    "\n",
    "    def _compute_layer_flow(self, attention_maps: Tuple[torch.Tensor], \n",
    "                           label_positions: List[int]) -> torch.Tensor:\n",
    "        \"\"\"Compute information flow for a set of layers.\"\"\"\n",
    "        flow = torch.zeros(len(attention_maps))\n",
    "        for i, attn in enumerate(attention_maps):\n",
    "            # Calculate flow to/from label positions\n",
    "            label_flow = attn[0, :, :, label_positions].mean()\n",
    "            flow[i] = label_flow\n",
    "        return flow\n",
    "\n",
    "    def compute_loyalty_metrics(self, base_logits: torch.Tensor, \n",
    "                              modified_logits: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"Compute label and word loyalty metrics.\"\"\"\n",
    "        # Label loyalty\n",
    "        base_pred = base_logits.argmax(dim=-1)\n",
    "        mod_pred = modified_logits.argmax(dim=-1)\n",
    "        label_loyalty = (base_pred == mod_pred).float().mean().item()\n",
    "\n",
    "        # Word loyalty (top-5 overlap)\n",
    "        base_top5 = torch.topk(base_logits, k=5, dim=-1).indices[0]\n",
    "        mod_top5 = torch.topk(modified_logits, k=5, dim=-1).indices[0]\n",
    "        word_overlap = len(set(base_top5.tolist()) & set(mod_top5.tolist())) / 5\n",
    "\n",
    "        return {\n",
    "            \"label_loyalty\": label_loyalty * 100,\n",
    "            \"word_loyalty\": word_overlap * 100\n",
    "        }\n",
    "\n",
    "    def block_information_flow(self, layer_idx: int, \n",
    "                             attention_mask: torch.Tensor) -> None:\n",
    "        \"\"\"Block information flow in specified layer.\"\"\"\n",
    "        def attention_hook(module, input_tensor, output_tensor):\n",
    "            modified_attention = output_tensor * attention_mask\n",
    "            return modified_attention\n",
    "        \n",
    "        # Register hook\n",
    "        layer = self.model.transformer.h[layer_idx].attn\n",
    "        handle = layer.register_forward_hook(attention_hook)\n",
    "        return handle\n",
    "\n",
    "    def visualize_flow(self, flow_metrics: Dict[str, torch.Tensor], \n",
    "                    title: str = \"Information Flow Analysis\"):\n",
    "        \"\"\"Visualize information flow patterns.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        layers = np.arange(len(flow_metrics[\"shallow_flow\"]))\n",
    "        # Detach tensors and move to CPU before plotting\n",
    "        shallow_flow = flow_metrics[\"shallow_flow\"].detach().cpu().numpy()\n",
    "        deep_flow = flow_metrics[\"deep_flow\"].detach().cpu().numpy()\n",
    "        \n",
    "        plt.plot(layers, shallow_flow, label=\"Shallow Layer Flow\")\n",
    "        plt.plot(layers, deep_flow, label=\"Deep Layer Flow\")\n",
    "        \n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(\"Information Flow\")\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    analyzer = LabelWordAnalyzer()\n",
    "\n",
    "    # Prepare demonstration data\n",
    "    demonstrations = [\n",
    "        {\"text\": \"This movie was amazing!\", \"label\": \"positive\"},\n",
    "        {\"text\": \"I really hated this film.\", \"label\": \"negative\"},\n",
    "        {\"text\": \"A beautiful masterpiece.\", \"label\": \"positive\"}\n",
    "    ]\n",
    "    query = \"The plot was confusing and boring.\"\n",
    "\n",
    "    # Get inputs and label positions\n",
    "    inputs = analyzer.prepare_input(demonstrations, query)\n",
    "    label_positions = [i for i, tok in enumerate(inputs[\"input_ids\"][0]) \n",
    "                      if tok in analyzer.tokenizer.encode([\"positive\", \"negative\"])]\n",
    "\n",
    "    # Compute baseline flow\n",
    "    flow_metrics = analyzer.compute_attention_flow(inputs[\"input_ids\"], \n",
    "                                                 label_positions)\n",
    "    analyzer.visualize_flow(flow_metrics)\n",
    "\n",
    "    # Analyze with blocked information flow\n",
    "    attention_mask = torch.ones_like(inputs[\"attention_mask\"])\n",
    "    attention_mask[:, label_positions] = 0\n",
    "    \n",
    "    handle = analyzer.block_information_flow(0, attention_mask)\n",
    "    outputs_blocked = analyzer.model(**inputs)\n",
    "    handle.remove()\n",
    "\n",
    "    # Compute loyalty metrics\n",
    "    outputs_normal = analyzer.model(**inputs)\n",
    "    loyalty = analyzer.compute_loyalty_metrics(outputs_normal.logits, \n",
    "                                            outputs_blocked.logits)\n",
    "    print(\"Loyalty Metrics:\", loyalty)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
